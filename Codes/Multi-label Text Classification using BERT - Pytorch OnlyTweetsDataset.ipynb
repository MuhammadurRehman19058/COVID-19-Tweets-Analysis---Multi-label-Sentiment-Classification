{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Multi-label Text Classification using BERT – The Mighty Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "228b425d698648988ab0066100f8c7e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_930beb017ba14c12b1d3f95005b0fabc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_62ed0b05e2214fa5b004fc9b427ac2db",
              "IPY_MODEL_84f2f87c5188492184e328ed4cc4598d"
            ]
          }
        },
        "930beb017ba14c12b1d3f95005b0fabc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62ed0b05e2214fa5b004fc9b427ac2db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3a51140785ae40c8b341efdae98b7e3e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5504be7d562140769a1a40f6d63c2598"
          }
        },
        "84f2f87c5188492184e328ed4cc4598d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8158189dfdfb434c9a25ff0f818d289f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:09&lt;00:00, 47.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa50626af83a4b6b9a2747147c438d4f"
          }
        },
        "3a51140785ae40c8b341efdae98b7e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5504be7d562140769a1a40f6d63c2598": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8158189dfdfb434c9a25ff0f818d289f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa50626af83a4b6b9a2747147c438d4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f9dbbb98157549cea39996661d8a24da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_54b0bf766f2a48038a0dd2a0821ffebe",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f0a6b549e04e4d5d8a3cd0941575a94a",
              "IPY_MODEL_b7d658d5248f43038d855cfe59a8237f"
            ]
          }
        },
        "54b0bf766f2a48038a0dd2a0821ffebe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0a6b549e04e4d5d8a3cd0941575a94a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3912392ae13f49b5988c05791881d7ff",
            "_dom_classes": [],
            "description": "Epoch: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f5bbf764d1743edb3422e6a53314f63"
          }
        },
        "b7d658d5248f43038d855cfe59a8237f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_93b8b7658fc848dab777c98a90a9a978",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [54:59&lt;00:00, 1649.72s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dbd5ea13f4704a9888d5f22ccb18fa22"
          }
        },
        "3912392ae13f49b5988c05791881d7ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9f5bbf764d1743edb3422e6a53314f63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93b8b7658fc848dab777c98a90a9a978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dbd5ea13f4704a9888d5f22ccb18fa22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ae26aee9d024912922121e5ca3df433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ea08bd8084c44be69132b4c4de07540b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_69853023494d4840a9269ac99aeca223",
              "IPY_MODEL_4327f9a11aec4e29976bb50831d4a75d"
            ]
          }
        },
        "ea08bd8084c44be69132b4c4de07540b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69853023494d4840a9269ac99aeca223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_74352b7250ee4703aeed41179bd2f567",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 247,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 247,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_15d6f495573c428ea71478623ba009dd"
          }
        },
        "4327f9a11aec4e29976bb50831d4a75d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d775bf9de5ee4361a0b380a2cfd6e5fd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 247/247 [54:59&lt;00:00, 13.36s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a3bffbc2593041a5bdec41b0f70e6786"
          }
        },
        "74352b7250ee4703aeed41179bd2f567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "15d6f495573c428ea71478623ba009dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d775bf9de5ee4361a0b380a2cfd6e5fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a3bffbc2593041a5bdec41b0f70e6786": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df12de27111a4f4daa9061a47898b285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_12387388b2124c36a95937bf0b79a571",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_203cbd7b56fd4cc398cfe1accc333ab9",
              "IPY_MODEL_577716cf81bc4d9a8de9053b832b78d9"
            ]
          }
        },
        "12387388b2124c36a95937bf0b79a571": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "203cbd7b56fd4cc398cfe1accc333ab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eb6477a120be4e34bff1195f3f967e83",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 247,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 247,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da3fdc66e6464ab8ad355919d5049ec1"
          }
        },
        "577716cf81bc4d9a8de9053b832b78d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e5ead36e56cf4094b7a3ab1dcfd54972",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 247/247 [41:46&lt;00:00, 10.15s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f2cb6f32bf184350a0668c5522781bda"
          }
        },
        "eb6477a120be4e34bff1195f3f967e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da3fdc66e6464ab8ad355919d5049ec1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5ead36e56cf4094b7a3ab1dcfd54972": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f2cb6f32bf184350a0668c5522781bda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "518cd5e264904bd48e89a97472925e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_987a1b76fe5c46fba46c1f5dfaa88879",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_16edefa6346b484dabdf081e7afd64a6",
              "IPY_MODEL_783a89c555a24d26849a9799eccedb64"
            ]
          }
        },
        "987a1b76fe5c46fba46c1f5dfaa88879": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "16edefa6346b484dabdf081e7afd64a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_adda65a8630d41b7a4c4821652356f76",
            "_dom_classes": [],
            "description": "Prediction Iteration: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 55,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 55,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6bcae39b2be143709d565ffd7b6f5bec"
          }
        },
        "783a89c555a24d26849a9799eccedb64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_74f9a6306dc84f63ada759954d14b774",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 55/55 [11:09&lt;00:00, 12.17s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c3c238eaf4e64e16867484f194ea3e2e"
          }
        },
        "adda65a8630d41b7a4c4821652356f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6bcae39b2be143709d565ffd7b6f5bec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74f9a6306dc84f63ada759954d14b774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c3c238eaf4e64e16867484f194ea3e2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1fd6d0e23c2f40718919f4e818d9bc4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_676135e6218a4fd988ff3f923cd3e7cc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_32c113c958bf478aba13f9b05e515e5e",
              "IPY_MODEL_10cc2afee1b5438da6bbec4449d6c9fb"
            ]
          }
        },
        "676135e6218a4fd988ff3f923cd3e7cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32c113c958bf478aba13f9b05e515e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3050f53c255f4630b485cf77e9e3e335",
            "_dom_classes": [],
            "description": "Emotion Labeling Iteration: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 14503,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 14503,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_633f4077addf491dae8e227f74af3ce9"
          }
        },
        "10cc2afee1b5438da6bbec4449d6c9fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a19b586ac609489fba1caccd4b07fde0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 14503/14503 [3:00:49&lt;00:00,  1.34it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a290488ad49f45f79caf755672cebadc"
          }
        },
        "3050f53c255f4630b485cf77e9e3e335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "633f4077addf491dae8e227f74af3ce9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a19b586ac609489fba1caccd4b07fde0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a290488ad49f45f79caf755672cebadc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6BbeLSbo4xF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "2d5574af-d6d6-4f81-95e2-7c8c66ea3de0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwImqsKWo_VF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dadec9d7-1650-4918-b725-cc52edcd772f"
      },
      "source": [
        "!pip install pytorch-pretrained-bert\n",
        "!pip install transformers\n",
        "!pip install fastai"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.5.1+cu101)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.14.9)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.16.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.9 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.17.9)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.9->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.0rc4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: fastai in /usr/local/lib/python3.6/dist-packages (1.0.61)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.18.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (3.2.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from fastai) (4.6.3)\n",
            "Requirement already satisfied: fastprogress>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from fastai) (0.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai) (20.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.4.1)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from fastai) (2.7.1)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.6/dist-packages (from fastai) (1.3.2)\n",
            "Requirement already satisfied: spacy>=2.0.18; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from fastai) (2.2.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (7.0.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastai) (0.7)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.5.1+cu101)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (1.0.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.23.0)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from fastai) (7.352.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai) (0.6.1+cu101)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->fastai) (1.12.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.7.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (47.3.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (2.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.1.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->fastai) (0.16.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.9)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teuXVsiDI12Q",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMXYP9pgosCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_pretrained_bert.tokenization import BertTokenizer, WordpieceTokenizer\n",
        "from pytorch_pretrained_bert.modeling import BertForPreTraining, BertPreTrainedModel, BertConfig, BertForMaskedLM\n",
        "from transformers import BertForSequenceClassification, BertModel \n",
        "\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import re\n",
        "from torch import Tensor\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "import torch.nn as nn\n",
        "from fastai.text import Tokenizer, Vocab\n",
        "import pandas as pd\n",
        "import collections\n",
        "import os\n",
        "import pdb\n",
        "from tqdm import tqdm, trange\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "# Installing Nvidia Apex\n",
        "# os.system('git clone https://github.com/NVIDIA/apex; cd apex; pip install -v --no-cache-dir' + \n",
        "#         ' --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./')\n",
        "# os.system('rm -rf apex/.git') # too many files, Kaggle fails\n",
        "\n",
        "import apex\n",
        "from sklearn.model_selection import train_test_split\n",
        "module_path = os.path.abspath(os.path.join('..'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from pytorch_pretrained_bert.optimization import BertAdam\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
        "                    level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2MBEKCwosCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_PATH=Path('/content/drive/My Drive/DL_Project/Tweets_Data/Corona_virus_Tweets/')\n",
        "\n",
        "# DATA_PATH.mkdir(exist_ok=True)\n",
        "\n",
        "PATH=Path('/content/drive/My Drive/DL_Project/Tweets_Data/Corona_virus_Tweets/')\n",
        "# PATH.mkdir(exist_ok=True)\n",
        "\n",
        "CLAS_DATA_PATH=PATH/'class'\n",
        "CLAS_DATA_PATH.mkdir(exist_ok=True)\n",
        "\n",
        "model_state_dict = None\n",
        "\n",
        "# BERT_PRETRAINED_PATH = Path('../trained_model/')\n",
        "BERT_PRETRAINED_PATH = Path('/content/drive/My Drive/DL_Project/uncased_L-12_H-768_A-12/')\n",
        "# BERT_PRETRAINED_PATH = Path('../../complaints/bert/pretrained-weights/cased_L-12_H-768_A-12/')\n",
        "# BERT_PRETRAINED_PATH = Path('../../complaints/bert/pretrained-weights/uncased_L-24_H-1024_A-16/')\n",
        "\n",
        "\n",
        "# BERT_FINETUNED_WEIGHTS = Path('../trained_model/toxic_comments')\n",
        "\n",
        "PYTORCH_PRETRAINED_BERT_CACHE = BERT_PRETRAINED_PATH/'cache/'\n",
        "PYTORCH_PRETRAINED_BERT_CACHE.mkdir(exist_ok=True)\n",
        "\n",
        "# output_model_file = os.path.join(BERT_FINETUNED_WEIGHTS, \"pytorch_model.bin\")\n",
        "\n",
        "# Load a trained model that you have fine-tuned\n",
        "# model_state_dict = torch.load(output_model_file)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmPmrEgOosCf",
        "colab_type": "text"
      },
      "source": [
        "### Model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28TS92ctosCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = {\n",
        "    \"train_size\": -1,\n",
        "    \"val_size\": -1,\n",
        "    \"full_data_dir\": DATA_PATH,\n",
        "    \"data_dir\": PATH,\n",
        "    \"task_name\": \"toxic_multilabel\",\n",
        "    \"no_cuda\": False,\n",
        "    \"bert_model\": BERT_PRETRAINED_PATH,\n",
        "    \"output_dir\": CLAS_DATA_PATH/'output',\n",
        "    \"max_seq_length\": 512,\n",
        "    \"do_train\": True,\n",
        "    \"do_eval\": True,\n",
        "    \"do_lower_case\": True,\n",
        "    \"train_batch_size\": 20,\n",
        "    \"eval_batch_size\": 20,\n",
        "    \"learning_rate\": 3e-5,\n",
        "    \"num_train_epochs\": 2.0,\n",
        "    \"warmup_proportion\": 0.1,\n",
        "    \"no_cuda\": False,\n",
        "    \"local_rank\": -1,\n",
        "    \"seed\": 40,\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"optimize_on_cpu\": False,\n",
        "    \"fp16\": False,\n",
        "    \"loss_scale\": 128\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1q5CF9nosCj",
        "colab_type": "text"
      },
      "source": [
        "### Model Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeFx1e40osCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertForMultiLabelSequenceClassification(BertForSequenceClassification):\n",
        "    \"\"\"BERT model for classification.\n",
        "    This module is composed of the BERT model with a linear layer on top of\n",
        "    the pooled output.\n",
        "    Params:\n",
        "        `config`: a BertConfig class instance with the configuration to build a new model.\n",
        "        `num_labels`: the number of classes for the classifier. Default = 2.\n",
        "    Inputs:\n",
        "        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "            `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "            a `sentence B` token (see BERT paper for more details).\n",
        "        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "            selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "            input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "            a batch has varying length sentences.\n",
        "        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]\n",
        "            with indices selected in [0, ..., num_labels].\n",
        "    Outputs:\n",
        "        if `labels` is not `None`:\n",
        "            Outputs the CrossEntropy classification loss of the output with the labels.\n",
        "        if `labels` is `None`:\n",
        "            Outputs the classification logits of shape [batch_size, num_labels].\n",
        "    Example usage:\n",
        "    ```python\n",
        "    # Already been converted into WordPiece token ids\n",
        "    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
        "    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
        "    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])\n",
        "    config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
        "        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
        "    num_labels = 2\n",
        "    model = BertForSequenceClassification(config, num_labels)\n",
        "    logits = model(input_ids, token_type_ids, input_mask)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self, config, num_labels=11):\n",
        "        super(BertForMultiLabelSequenceClassification, self).__init__(config)\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = torch.nn.Linear(config.hidden_size, num_labels)\n",
        "\n",
        "        self.epoch_train_loss = list()\n",
        "        self.epoch_train_accuracy = list()\n",
        "        \n",
        "        self.epoch_validation_loss = list()\n",
        "        self.epoch_validation_accuracy = list()\n",
        "        \n",
        "        self.epoch_test_loss = list()\n",
        "        self.epoch_test_accuracy = list()\n",
        "        self.epoch_test_precision = list()\n",
        "        self.epoch_test_recall = list()\n",
        "        \n",
        "        self.train_batch_true = list()\n",
        "        self.train_batch_predicted = list()\n",
        "        self.train_batch_precision = list()\n",
        "        self.train_batch_recall = list()\n",
        "\n",
        "        self.validation_batch_true = list()\n",
        "        self.validation_batch_predicted = list()\n",
        "        self.validation_batch_precision = list()\n",
        "        self.validation_batch_recall = list()\n",
        "        \n",
        "        self.test_batch_true = list()\n",
        "        self.test_batch_predicted = list()\n",
        "        self.test_batch_precision = list()\n",
        "        self.test_batch_recall = list()\n",
        "        \n",
        "        self.train_accuracy = 0\n",
        "        self.validation_accuracy = 0\n",
        "        self.test_accuracy = 0\n",
        "        \n",
        "        self.train_loss = 0\n",
        "        self.validation_loss = 0\n",
        "        self.test_loss = 0\n",
        "         \n",
        "        # self.apply(self.init_bert_weights)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = BCEWithLogitsLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
        "            return loss, logits\n",
        "        else:\n",
        "            return logits\n",
        "        \n",
        "\n",
        "    def get_ecoder_layers_count(self):\n",
        "      nos =0\n",
        "      for param in self.bert.parameters():\n",
        "            nos += 1\n",
        "      return nos\n",
        "\n",
        "\n",
        "    def unfreeze_bert_encoder_count(self, count):\n",
        "        i = 0\n",
        "        nos = self.get_ecoder_layers_count()\n",
        "        for param in self.bert.parameters():\n",
        "            i += 1\n",
        "            if i > (nos-count):\n",
        "              param.requires_grad = True\n",
        "            else:\n",
        "              param.requires_grad = False\n",
        "    \n",
        "    def freeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "    \n",
        "    def unfreeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = True"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9fdqKi9osCm",
        "colab_type": "text"
      },
      "source": [
        "### Data representation Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXQoVK0bosCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, labels=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "\n",
        "        Args:\n",
        "            guid: Unique id for the example.\n",
        "            text_a: string. The untokenized text of the first sequence. For single\n",
        "            sequence tasks, only this sequence must be specified.\n",
        "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "            Only must be specified for sequence pair tasks.\n",
        "            labels: (Optional) [string]. The label of the example. This should be\n",
        "            specified for train and dev examples, but not for test examples.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, input_mask, segment_ids, label_ids):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_ids = label_ids"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xMgFckPosCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataProcessor(object):\n",
        "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "    \n",
        "    def get_test_examples(self, data_dir, data_file_name, size=-1):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
        "        raise NotImplementedError() \n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
        "        raise NotImplementedError()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAGmGjjgosCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiLabelTextProcessor(DataProcessor):\n",
        "    \n",
        "    def __init__(self, data_dir):\n",
        "        self.data_dir = data_dir\n",
        "        self.labels = None\n",
        "        print (\"root Directory \", self.data_dir)\n",
        "    \n",
        "    def get_train_examples(self, data_dir, size=-1):\n",
        "        filename = 'train.csv'\n",
        "        logger.info(\"LOOKING AT {}\".format(os.path.join(data_dir, filename)))\n",
        "        if size == -1:\n",
        "            data_df = pd.read_csv(os.path.join(data_dir, filename))\n",
        "#             data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
        "            return self._create_examples(data_df, \"train\")\n",
        "        else:\n",
        "            data_df = pd.read_csv(os.path.join(data_dir, filename),  sep = '\\t')\n",
        "#             data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
        "            return self._create_examples(data_df.sample(size), \"train\")\n",
        "        \n",
        "    def get_dev_examples(self, data_dir, size=-1):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        filename = 'dev.csv'\n",
        "        if size == -1:\n",
        "            data_df = pd.read_csv(os.path.join(data_dir, filename))\n",
        "#             data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
        "            return self._create_examples(data_df, \"dev\")\n",
        "        else:\n",
        "            data_df = pd.read_csv(os.path.join(data_dir, filename))\n",
        "#             data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
        "            return self._create_examples(data_df.sample(size), \"dev\")\n",
        "    \n",
        "    def get_test_examples(self, data_dir, data_file_name, size=-1):\n",
        "        data_df = pd.read_csv(os.path.join(data_dir, data_file_name))\n",
        "#         data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
        "        if size == -1:\n",
        "            return self._create_examples(data_df, \"test\")\n",
        "        else:\n",
        "            return self._create_examples(data_df.sample(size), \"test\")\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        if self.labels == None:\n",
        "            self.labels = list(pd.read_csv(os.path.join(self.data_dir, \"classes.txt\"),header=None, sep = '\\t').values)\n",
        "        return self.labels\n",
        "\n",
        "    def _create_examples(self, df, set_type, labels_available=True):\n",
        "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "        examples = []\n",
        "        for (i, row) in enumerate(df.values):\n",
        "            guid = row[0]\n",
        "            text_a = row[3]\n",
        "            if labels_available:\n",
        "                labels = row[11:]\n",
        "            else:\n",
        "                labels = []\n",
        "            examples.append(\n",
        "                InputExample(guid=guid, text_a=text_a, labels=labels))\n",
        "        return examples\n",
        "        "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rzqp-TaZosCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer):\n",
        "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
        "\n",
        "#     label_map = {label : i for i, label in enumerate(label_list)}\n",
        "\n",
        "    features = []\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        tokens_a = tokenizer.tokenize(example.text_a)\n",
        "\n",
        "        tokens_b = None\n",
        "        if example.text_b:\n",
        "            tokens_b = tokenizer.tokenize(example.text_b)\n",
        "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "            # length is less than the specified length.\n",
        "            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
        "        else:\n",
        "            # Account for [CLS] and [SEP] with \"- 2\"\n",
        "            if len(tokens_a) > max_seq_length - 2:\n",
        "                tokens_a = tokens_a[:(max_seq_length - 2)]\n",
        "\n",
        "        # The convention in BERT is:\n",
        "        # (a) For sequence pairs:\n",
        "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "        #  type_ids: 0   0  0    0    0     0       0 0    1  1  1  1   1 1\n",
        "        # (b) For single sequences:\n",
        "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
        "        #  type_ids: 0   0   0   0  0     0 0\n",
        "        #\n",
        "        # Where \"type_ids\" are used to indicate whether this is the first\n",
        "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "        # embedding vector (and position vector). This is not *strictly* necessary\n",
        "        # since the [SEP] token unambigiously separates the sequences, but it makes\n",
        "        # it easier for the model to learn the concept of sequences.\n",
        "        #\n",
        "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "        # the entire model is fine-tuned.\n",
        "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
        "        segment_ids = [0] * len(tokens)\n",
        "\n",
        "        if tokens_b:\n",
        "            tokens += tokens_b + [\"[SEP]\"]\n",
        "            segment_ids += [1] * (len(tokens_b) + 1)\n",
        "\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "        # tokens are attended to.\n",
        "        input_mask = [1] * len(input_ids)\n",
        "\n",
        "        # Zero-pad up to the sequence length.\n",
        "        padding = [0] * (max_seq_length - len(input_ids))\n",
        "        input_ids += padding\n",
        "        input_mask += padding\n",
        "        segment_ids += padding\n",
        "\n",
        "        assert len(input_ids) == max_seq_length\n",
        "        assert len(input_mask) == max_seq_length\n",
        "        assert len(segment_ids) == max_seq_length\n",
        "        \n",
        "        labels_ids = []\n",
        "        for label in example.labels:\n",
        "            labels_ids.append(float(label))\n",
        "\n",
        "#         label_id = label_map[example.label]\n",
        "        if ex_index < 0:\n",
        "            logger.info(\"*** Example ***\")\n",
        "            logger.info(\"guid: %s\" % (example.guid))\n",
        "            logger.info(\"tokens: %s\" % \" \".join(\n",
        "                    [str(x) for x in tokens]))\n",
        "            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
        "            logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
        "            logger.info(\n",
        "                    \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
        "            logger.info(\"label: %s (id = %s)\" % (example.labels, labels_ids))\n",
        "\n",
        "        features.append(\n",
        "                InputFeatures(input_ids=input_ids,\n",
        "                              input_mask=input_mask,\n",
        "                              segment_ids=segment_ids,\n",
        "                              label_ids=labels_ids))\n",
        "    return features"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22CXpwG9osCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "    # This is a simple heuristic which will always truncate the longer sequence\n",
        "    # one token at a time. This makes more sense than truncating an equal percent\n",
        "    # of tokens from each, since if one sequence is very short then each token\n",
        "    # that's truncated likely contains more information than a longer sequence.\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWhZZ_SYosCz",
        "colab_type": "text"
      },
      "source": [
        "### Metric Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW-87dTYosCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(out, labels):\n",
        "    outputs = np.argmax(out, axis=1)\n",
        "    return np.sum(outputs == labels)\n",
        "\n",
        "def accuracy_thresh(y_pred:Tensor, y_true:Tensor, thresh:float=0.5, sigmoid:bool=True):\n",
        "    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n",
        "    if sigmoid: y_pred = y_pred.sigmoid()\n",
        "#     return ((y_pred>thresh)==y_true.byte()).float().mean().item()\n",
        "    return np.mean(((y_pred>thresh)==y_true.byte()).float().cpu().numpy(), axis=1).sum()\n",
        "\n",
        "\n",
        "def accuracy_thresh_test(y_pred:Tensor, y_true:Tensor, thresh:float=0.5, sigmoid:bool=True):\n",
        "    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n",
        "    if sigmoid: y_pred = y_pred.sigmoid()\n",
        "#     return ((y_pred>thresh)==y_true.byte()).float().mean().item()\n",
        "    return np.mean((y_pred>thresh)==y_true.float()).sum()\n",
        "\n",
        "\n",
        "def fbeta(y_pred:Tensor, y_true:Tensor, thresh:float=0.2, beta:float=2, eps:float=1e-9, sigmoid:bool=True):\n",
        "    \"Computes the f_beta between `preds` and `targets`\"\n",
        "    beta2 = beta ** 2\n",
        "    if sigmoid: y_pred = y_pred.sigmoid()\n",
        "    y_pred = (y_pred>thresh).float()\n",
        "    y_true = y_true.float()\n",
        "    TP = (y_pred*y_true).sum(dim=1)\n",
        "    prec = TP/(y_pred.sum(dim=1)+eps)\n",
        "    rec = TP/(y_true.sum(dim=1)+eps)\n",
        "    res = (prec*rec)/(prec*beta2+rec+eps)*(1+beta2)\n",
        "    return res.mean().item(),prec, rec"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePsoi7YWosC1",
        "colab_type": "text"
      },
      "source": [
        "### Training Warmup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGmwFFb8osC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def warmup_linear(x, warmup=0.002):\n",
        "    if x < warmup:\n",
        "        return x/warmup\n",
        "    return 1.0 - x"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av0p85CzosC4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ecf3be37-46e6-466e-80d6-21aba997453a"
      },
      "source": [
        "processors = {\n",
        "    \"toxic_multilabel\": MultiLabelTextProcessor\n",
        "}\n",
        "\n",
        "# Setup GPU parameters\n",
        "\n",
        "if args[\"local_rank\"] == -1 or args[\"no_cuda\"]:\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args[\"no_cuda\"] else \"cpu\")\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "#     n_gpu = 1\n",
        "else:\n",
        "    torch.cuda.set_device(args['local_rank'])\n",
        "    device = torch.device(\"cuda\", args['local_rank'])\n",
        "    n_gpu = 1\n",
        "    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
        "    torch.distributed.init_process_group(backend='nccl')\n",
        "logger.info(\"device: {} n_gpu: {}, distributed training: {}, 16-bits training: {}\".format(\n",
        "        device, n_gpu, bool(args['local_rank'] != -1), args['fp16']))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07/01/2020 11:01:31 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzkDXJU6osC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args['train_batch_size'] = int(args['train_batch_size'] / args['gradient_accumulation_steps'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pK34ee3osC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.seed(args['seed'])\n",
        "np.random.seed(args['seed'])\n",
        "torch.manual_seed(args['seed'])\n",
        "if n_gpu > 0:\n",
        "    torch.cuda.manual_seed_all(args['seed'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uA6T3ZrosDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "task_name = args['task_name'].lower()\n",
        "\n",
        "if task_name not in processors:\n",
        "    raise ValueError(\"Task not found: %s\" % (task_name))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn512PxLosDC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c7d4150-99be-4220-952e-51f30fab8cf5"
      },
      "source": [
        "processor = processors[task_name](args['data_dir'])\n",
        "label_list = processor.get_labels()\n",
        "num_labels = len(label_list)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root Directory  /content/drive/My Drive/DL_Project/Tweets_Data/Corona_virus_Tweets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eVJ-Ri2osDE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "064fb83d-798b-4682-971e-fa71fcfb9e98"
      },
      "source": [
        "label_list"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array(['anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise',\n",
              "        'trust'], dtype=object)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TvtmMZrosDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8067b28f-5663-4ed8-c291-1fca95f858c5"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(args['bert_model'], do_lower_case=args['do_lower_case'])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07/01/2020 11:01:35 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file /content/drive/My Drive/DL_Project/uncased_L-12_H-768_A-12/vocab.txt\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI7LpfZmosDI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef85f5a3-ed75-44e4-8f12-10753cf129a3"
      },
      "source": [
        "train_examples = None\n",
        "num_train_steps = None\n",
        "if args['do_train']:\n",
        "    train_examples = processor.get_train_examples(args['full_data_dir'], size=args['train_size'])\n",
        "#     train_examples = processor.get_train_examples(args['data_dir'], size=args['train_size'])\n",
        "    num_train_steps = int(\n",
        "        len(train_examples) / args['train_batch_size'] / args['gradient_accumulation_steps'] * args['num_train_epochs'])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07/01/2020 11:01:36 - INFO - __main__ -   LOOKING AT /content/drive/My Drive/DL_Project/Tweets_Data/Corona_virus_Tweets/train.csv\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXsugFhKosDK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741,
          "referenced_widgets": [
            "228b425d698648988ab0066100f8c7e1",
            "930beb017ba14c12b1d3f95005b0fabc",
            "62ed0b05e2214fa5b004fc9b427ac2db",
            "84f2f87c5188492184e328ed4cc4598d",
            "3a51140785ae40c8b341efdae98b7e3e",
            "5504be7d562140769a1a40f6d63c2598",
            "8158189dfdfb434c9a25ff0f818d289f",
            "fa50626af83a4b6b9a2747147c438d4f"
          ]
        },
        "outputId": "f66080eb-1311-4a75-fb3f-0f9992c31bfe"
      },
      "source": [
        "# Prepare model\n",
        "def get_model():\n",
        "#     pdb.set_trace()\n",
        "#     if model_state_dict:\n",
        "#         model = BertForMultiLabelSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 11, state_dict=model_state_dict)\n",
        "#     else:\n",
        "    model = BertForMultiLabelSequenceClassification.from_pretrained('bert-base-uncased', num_labels = num_labels)\n",
        "    return model\n",
        "\n",
        "model = get_model()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07/01/2020 11:01:37 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "07/01/2020 11:01:37 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "07/01/2020 11:01:37 - INFO - filelock -   Lock 139623565225600 acquired on /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "07/01/2020 11:01:37 - INFO - transformers.file_utils -   https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp2e516_rn\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "228b425d698648988ab0066100f8c7e1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "07/01/2020 11:01:46 - INFO - transformers.file_utils -   storing https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin in cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "07/01/2020 11:01:46 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "07/01/2020 11:01:46 - INFO - filelock -   Lock 139623565225600 released on /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "07/01/2020 11:01:46 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "07/01/2020 11:01:52 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "07/01/2020 11:01:52 - WARNING - transformers.modeling_utils -   Some weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5txztoIosDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "if args['fp16']:\n",
        "    model.half()\n",
        "model.to(device)\n",
        "if args['local_rank'] != -1:\n",
        "    try:\n",
        "        from apex.parallel import DistributedDataParallel as DDP\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
        "\n",
        "    model = DDP(model)\n",
        "elif n_gpu > 1:\n",
        "    model = torch.nn.DataParallel(model)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud6W504hosDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim.lr_scheduler import _LRScheduler, Optimizer\n",
        "\n",
        "class CyclicLR(object):\n",
        "    \"\"\"Sets the learning rate of each parameter group according to\n",
        "    cyclical learning rate policy (CLR). The policy cycles the learning\n",
        "    rate between two boundaries with a constant frequency, as detailed in\n",
        "    the paper `Cyclical Learning Rates for Training Neural Networks`_.\n",
        "    The distance between the two boundaries can be scaled on a per-iteration\n",
        "    or per-cycle basis.\n",
        "    Cyclical learning rate policy changes the learning rate after every batch.\n",
        "    `batch_step` should be called after a batch has been used for training.\n",
        "    To resume training, save `last_batch_iteration` and use it to instantiate `CycleLR`.\n",
        "    This class has three built-in policies, as put forth in the paper:\n",
        "    \"triangular\":\n",
        "        A basic triangular cycle w/ no amplitude scaling.\n",
        "    \"triangular2\":\n",
        "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
        "    \"exp_range\":\n",
        "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each\n",
        "        cycle iteration.\n",
        "    This implementation was adapted from the github repo: `bckenstler/CLR`_\n",
        "    Args:\n",
        "        optimizer (Optimizer): Wrapped optimizer.\n",
        "        base_lr (float or list): Initial learning rate which is the\n",
        "            lower boundary in the cycle for eachparam groups.\n",
        "            Default: 0.001\n",
        "        max_lr (float or list): Upper boundaries in the cycle for\n",
        "            each parameter group. Functionally,\n",
        "            it defines the cycle amplitude (max_lr - base_lr).\n",
        "            The lr at any cycle is the sum of base_lr\n",
        "            and some scaling of the amplitude; therefore\n",
        "            max_lr may not actually be reached depending on\n",
        "            scaling function. Default: 0.006\n",
        "        step_size (int): Number of training iterations per\n",
        "            half cycle. Authors suggest setting step_size\n",
        "            2-8 x training iterations in epoch. Default: 2000\n",
        "        mode (str): One of {triangular, triangular2, exp_range}.\n",
        "            Values correspond to policies detailed above.\n",
        "            If scale_fn is not None, this argument is ignored.\n",
        "            Default: 'triangular'\n",
        "        gamma (float): Constant in 'exp_range' scaling function:\n",
        "            gamma**(cycle iterations)\n",
        "            Default: 1.0\n",
        "        scale_fn (function): Custom scaling policy defined by a single\n",
        "            argument lambda function, where\n",
        "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
        "            mode paramater is ignored\n",
        "            Default: None\n",
        "        scale_mode (str): {'cycle', 'iterations'}.\n",
        "            Defines whether scale_fn is evaluated on\n",
        "            cycle number or cycle iterations (training\n",
        "            iterations since start of cycle).\n",
        "            Default: 'cycle'\n",
        "        last_batch_iteration (int): The index of the last batch. Default: -1\n",
        "    Example:\n",
        "        >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "        >>> scheduler = torch.optim.CyclicLR(optimizer)\n",
        "        >>> data_loader = torch.utils.data.DataLoader(...)\n",
        "        >>> for epoch in range(10):\n",
        "        >>>     for batch in data_loader:\n",
        "        >>>         scheduler.batch_step()\n",
        "        >>>         train_batch(...)\n",
        "    .. _Cyclical Learning Rates for Training Neural Networks: https://arxiv.org/abs/1506.01186\n",
        "    .. _bckenstler/CLR: https://github.com/bckenstler/CLR\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, optimizer, base_lr=1e-3, max_lr=6e-3,\n",
        "                 step_size=2000, mode='triangular', gamma=1.,\n",
        "                 scale_fn=None, scale_mode='cycle', last_batch_iteration=-1):\n",
        "\n",
        "#         if not isinstance(optimizer, Optimizer):\n",
        "#             raise TypeError('{} is not an Optimizer'.format(\n",
        "#                 type(optimizer).__name__))\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        if isinstance(base_lr, list) or isinstance(base_lr, tuple):\n",
        "            if len(base_lr) != len(optimizer.param_groups):\n",
        "                raise ValueError(\"expected {} base_lr, got {}\".format(\n",
        "                    len(optimizer.param_groups), len(base_lr)))\n",
        "            self.base_lrs = list(base_lr)\n",
        "        else:\n",
        "            self.base_lrs = [base_lr] * len(optimizer.param_groups)\n",
        "\n",
        "        if isinstance(max_lr, list) or isinstance(max_lr, tuple):\n",
        "            if len(max_lr) != len(optimizer.param_groups):\n",
        "                raise ValueError(\"expected {} max_lr, got {}\".format(\n",
        "                    len(optimizer.param_groups), len(max_lr)))\n",
        "            self.max_lrs = list(max_lr)\n",
        "        else:\n",
        "            self.max_lrs = [max_lr] * len(optimizer.param_groups)\n",
        "\n",
        "        self.step_size = step_size\n",
        "\n",
        "        if mode not in ['triangular', 'triangular2', 'exp_range'] \\\n",
        "                and scale_fn is None:\n",
        "            raise ValueError('mode is invalid and scale_fn is None')\n",
        "\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "\n",
        "        if scale_fn is None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = self._triangular_scale_fn\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = self._triangular2_scale_fn\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = self._exp_range_scale_fn\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "\n",
        "        self.batch_step(last_batch_iteration + 1)\n",
        "        self.last_batch_iteration = last_batch_iteration\n",
        "\n",
        "    def batch_step(self, batch_iteration=None):\n",
        "        if batch_iteration is None:\n",
        "            batch_iteration = self.last_batch_iteration + 1\n",
        "        self.last_batch_iteration = batch_iteration\n",
        "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "    def _triangular_scale_fn(self, x):\n",
        "        return 1.\n",
        "\n",
        "    def _triangular2_scale_fn(self, x):\n",
        "        return 1 / (2. ** (x - 1))\n",
        "\n",
        "    def _exp_range_scale_fn(self, x):\n",
        "        return self.gamma**(x)\n",
        "\n",
        "    def get_lr(self):\n",
        "        step_size = float(self.step_size)\n",
        "        cycle = np.floor(1 + self.last_batch_iteration / (2 * step_size))\n",
        "        x = np.abs(self.last_batch_iteration / step_size - 2 * cycle + 1)\n",
        "\n",
        "        lrs = []\n",
        "        param_lrs = zip(self.optimizer.param_groups, self.base_lrs, self.max_lrs)\n",
        "        for param_group, base_lr, max_lr in param_lrs:\n",
        "            base_height = (max_lr - base_lr) * np.maximum(0, (1 - x))\n",
        "            if self.scale_mode == 'cycle':\n",
        "                lr = base_lr + base_height * self.scale_fn(cycle)\n",
        "            else:\n",
        "                lr = base_lr + base_height * self.scale_fn(self.last_batch_iteration)\n",
        "            lrs.append(lr)\n",
        "        return lrs"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrEFnyq5osDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare optimizer\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "t_total = num_train_steps\n",
        "if args['local_rank'] != -1:\n",
        "    t_total = t_total // torch.distributed.get_world_size()\n",
        "if args['fp16']:\n",
        "    try:\n",
        "        from apex.optimizers import FP16_Optimizer\n",
        "        from apex.optimizers import FusedAdam\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
        "\n",
        "    optimizer = FusedAdam(optimizer_grouped_parameters,\n",
        "                          lr=args['learning_rate'],\n",
        "                          bias_correction=False,\n",
        "                          max_grad_norm=1.0)\n",
        "    if args['loss_scale'] == 0:\n",
        "        optimizer = FP16_Optimizer(optimizer, dynamic_loss_scale=True)\n",
        "    else:\n",
        "        optimizer = FP16_Optimizer(optimizer, static_loss_scale=args['loss_scale'])\n",
        "\n",
        "else:\n",
        "    optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                         lr=args['learning_rate'],\n",
        "                         warmup=args['warmup_proportion'],\n",
        "                         t_total=t_total)\n",
        "\n",
        "scheduler = CyclicLR(optimizer, base_lr=2e-5, max_lr=5e-5, step_size=2500, last_batch_iteration=0)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBKhFqDDosDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Eval Fn\n",
        "eval_examples = processor.get_dev_examples(args['data_dir'], size=args['val_size'])\n",
        "def eval():\n",
        "    args['output_dir'].mkdir(exist_ok=True)\n",
        "\n",
        "    \n",
        "    eval_features = convert_examples_to_features(\n",
        "        eval_examples, label_list, args['max_seq_length'], tokenizer)\n",
        "    logger.info(\"***** Running evaluation *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(eval_examples))\n",
        "    logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n",
        "    all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
        "    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
        "    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
        "    all_label_ids = torch.tensor([f.label_ids for f in eval_features], dtype=torch.float)\n",
        "    eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
        "\n",
        "    # Run prediction for full data\n",
        "    eval_sampler = SequentialSampler(eval_data)\n",
        "    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args['eval_batch_size'])\n",
        "    \n",
        "    all_logits = None\n",
        "    all_labels = None\n",
        "    \n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    for input_ids, input_mask, segment_ids, label_ids in eval_dataloader:\n",
        "        input_ids = input_ids.to(device)\n",
        "        input_mask = input_mask.to(device)\n",
        "        segment_ids = segment_ids.to(device)\n",
        "        label_ids = label_ids.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            tmp_eval_loss, logit = model(input_ids, segment_ids, input_mask, label_ids)\n",
        "            logits = model(input_ids, segment_ids, input_mask)\n",
        "\n",
        "\n",
        "#         logits = logits.detach().cpu().numpy()\n",
        "#         label_ids = label_ids.to('cpu').numpy()\n",
        "#         tmp_eval_accuracy = accuracy(logits, label_ids)\n",
        "        tmp_eval_accuracy = accuracy_thresh(logits, label_ids)\n",
        "\n",
        "        res, precision, recall = fbeta(logits, label_ids) \n",
        "        \n",
        "        ########### saving for later use ################\n",
        "        model.validation_batch_true.append(label_ids)  \n",
        "        model.validation_batch_predicted.append(logits) \n",
        "        model.validation_batch_precision.append(precision)\n",
        "        model.validation_batch_recall.append(recall)\n",
        "\n",
        "        if all_logits is None:\n",
        "            all_logits = logits.detach().cpu().numpy()\n",
        "        else:\n",
        "            all_logits = np.concatenate((all_logits, logits.detach().cpu().numpy()), axis=0)\n",
        "            \n",
        "        if all_labels is None:\n",
        "            all_labels = label_ids.detach().cpu().numpy()\n",
        "        else:    \n",
        "            all_labels = np.concatenate((all_labels, label_ids.detach().cpu().numpy()), axis=0)\n",
        "        \n",
        "\n",
        "        eval_loss += tmp_eval_loss.mean().item()\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        nb_eval_examples += input_ids.size(0)\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_examples\n",
        "    \n",
        "#     ROC-AUC calcualation\n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    \n",
        "    for i in range(num_labels):\n",
        "        fpr[i], tpr[i], _ = roc_curve(all_labels[:, i], all_logits[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "        \n",
        "    # Compute micro-average ROC curve and ROC area\n",
        "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(all_labels.ravel(), all_logits.ravel())\n",
        "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "    result = {'eval_loss': eval_loss,\n",
        "              'eval_accuracy': eval_accuracy,\n",
        "#               'loss': tr_loss/nb_tr_steps,\n",
        "              'roc_auc': roc_auc  }\n",
        "\n",
        "  \n",
        "    model.epoch_validation_loss.append(eval_loss) \n",
        "    model.epoch_validation_accuracy.append(eval_accuracy) \n",
        "\n",
        "\n",
        "    output_eval_file = os.path.join(args['output_dir'], \"eval_results.txt\")\n",
        "    with open(output_eval_file, \"w\") as writer:\n",
        "        logger.info(\"***** Eval results *****\")\n",
        "        for key in sorted(result.keys()):\n",
        "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "    return result"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM4oqizhosDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features = convert_examples_to_features(train_examples, label_list, args['max_seq_length'], tokenizer)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8MCL4OjosDX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "d7c9c7ce-b145-4825-d18c-8946c36257bb"
      },
      "source": [
        "logger.info(\"***** Running training *****\")\n",
        "logger.info(\"  Num examples = %d\", len(train_examples))\n",
        "logger.info(\"  Batch size = %d\", args['train_batch_size'])\n",
        "logger.info(\"  Num steps = %d\", num_train_steps)\n",
        "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
        "all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
        "all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
        "all_label_ids = torch.tensor([f.label_ids for f in train_features], dtype=torch.float)\n",
        "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
        "if args['local_rank'] == -1:\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "else:\n",
        "    train_sampler = DistributedSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args['train_batch_size'])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07/01/2020 11:05:03 - INFO - __main__ -   ***** Running training *****\n",
            "07/01/2020 11:05:03 - INFO - __main__ -     Num examples = 4936\n",
            "07/01/2020 11:05:03 - INFO - __main__ -     Batch size = 20\n",
            "07/01/2020 11:05:03 - INFO - __main__ -     Num steps = 493\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1-SZzqSosDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook as tqdm"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa-x8Dk7osDc",
        "colab_type": "text"
      },
      "source": [
        "### Train Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxfWBbAMosDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(num_epocs=args['num_train_epochs']):\n",
        "    global_step = 0\n",
        "    model.train()\n",
        "    for i_ in tqdm(range(int(num_epocs)), desc=\"Epoch\"):\n",
        "\n",
        "        model.train_batch_true.clear()\n",
        "        model.train_batch_predicted.clear()\n",
        "        model.train_batch_precision.clear()\n",
        "        model.train_batch_recall.clear()\n",
        "        \n",
        "        model.validation_batch_true.clear()\n",
        "        model.validation_batch_predicted.clear()\n",
        "        model.validation_batch_precision.clear()\n",
        "        model.validation_batch_recall.clear()\n",
        "\n",
        "\n",
        "        tr_loss = 0\n",
        "        nb_tr_examples, nb_tr_steps = 0, 0\n",
        "        for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
        "\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, input_mask, segment_ids, label_ids = batch\n",
        "            loss, logits = model(input_ids, segment_ids, input_mask, label_ids)\n",
        "\n",
        "            if n_gpu > 1:\n",
        "                loss = loss.mean() # mean() to average on multi-gpu.\n",
        "            if args['gradient_accumulation_steps'] > 1:\n",
        "                loss = loss / args['gradient_accumulation_steps']\n",
        "\n",
        "            if args['fp16']:\n",
        "                optimizer.backward(loss)\n",
        "            else:\n",
        "                loss.backward()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            nb_tr_examples += input_ids.size(0)\n",
        "            nb_tr_steps += 1\n",
        "            if (step + 1) % args['gradient_accumulation_steps'] == 0:\n",
        "    #             scheduler.batch_step()\n",
        "                # modify learning rate with special warm up BERT uses\n",
        "                lr_this_step = args['learning_rate'] * warmup_linear(global_step/t_total, args['warmup_proportion'])\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = lr_this_step\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "\n",
        "            res, precision, recall = fbeta(logits, label_ids) \n",
        "\n",
        "            model.train_batch_true.append(label_ids) \n",
        "            model.train_batch_predicted.append(logits) \n",
        "            model.train_batch_precision.append(precision)\n",
        "            model.train_batch_recall.append(recall)\n",
        "        \n",
        "        model.epoch_train_loss.append(tr_loss / nb_tr_steps) \n",
        "        model.epoch_train_accuracy.append(tr_loss / nb_tr_steps) \n",
        "\n",
        "\n",
        "        logger.info('Loss after epoc {}'.format(tr_loss / nb_tr_steps))\n",
        "        logger.info('Eval after epoc {}'.format(i_+1))\n",
        "        eval()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sxiBim2Y2PT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b21c3d8a-f696-4919-b36a-12263778266b"
      },
      "source": [
        "model.get_ecoder_layers_count()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uXSHap9osDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.unfreeze_bert_encoder_count(110)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE5nv3eMosDj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617,
          "referenced_widgets": [
            "f9dbbb98157549cea39996661d8a24da",
            "54b0bf766f2a48038a0dd2a0821ffebe",
            "f0a6b549e04e4d5d8a3cd0941575a94a",
            "b7d658d5248f43038d855cfe59a8237f",
            "3912392ae13f49b5988c05791881d7ff",
            "9f5bbf764d1743edb3422e6a53314f63",
            "93b8b7658fc848dab777c98a90a9a978",
            "dbd5ea13f4704a9888d5f22ccb18fa22",
            "9ae26aee9d024912922121e5ca3df433",
            "ea08bd8084c44be69132b4c4de07540b",
            "69853023494d4840a9269ac99aeca223",
            "4327f9a11aec4e29976bb50831d4a75d",
            "74352b7250ee4703aeed41179bd2f567",
            "15d6f495573c428ea71478623ba009dd",
            "d775bf9de5ee4361a0b380a2cfd6e5fd",
            "a3bffbc2593041a5bdec41b0f70e6786",
            "df12de27111a4f4daa9061a47898b285",
            "12387388b2124c36a95937bf0b79a571",
            "203cbd7b56fd4cc398cfe1accc333ab9",
            "577716cf81bc4d9a8de9053b832b78d9",
            "eb6477a120be4e34bff1195f3f967e83",
            "da3fdc66e6464ab8ad355919d5049ec1",
            "e5ead36e56cf4094b7a3ab1dcfd54972",
            "f2cb6f32bf184350a0668c5522781bda"
          ]
        },
        "outputId": "c55de306-a5b4-4787-c95a-67d412216864"
      },
      "source": [
        "fit()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9dbbb98157549cea39996661d8a24da",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=2.0, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ae26aee9d024912922121e5ca3df433",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=247.0, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n",
            "07/01/2020 11:16:00 - INFO - __main__ -   Loss after epoc 0.4056503650871848\n",
            "07/01/2020 11:16:00 - INFO - __main__ -   Eval after epoc 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "07/01/2020 11:16:00 - INFO - __main__ -   ***** Running evaluation *****\n",
            "07/01/2020 11:16:00 - INFO - __main__ -     Num examples = 1063\n",
            "07/01/2020 11:16:00 - INFO - __main__ -     Batch size = 20\n",
            "07/01/2020 11:18:16 - INFO - __main__ -   ***** Eval results *****\n",
            "07/01/2020 11:18:16 - INFO - __main__ -     eval_accuracy = 0.8720601852054543\n",
            "07/01/2020 11:18:16 - INFO - __main__ -     eval_loss = 0.3726839318319603\n",
            "07/01/2020 11:18:16 - INFO - __main__ -     roc_auc = {0: 0.5128008082458271, 'micro': 0.6297108722865433}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df12de27111a4f4daa9061a47898b285",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=247.0, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "07/01/2020 11:28:53 - INFO - __main__ -   Loss after epoc 0.37032570095680023\n",
            "07/01/2020 11:28:53 - INFO - __main__ -   Eval after epoc 2\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "07/01/2020 11:28:54 - INFO - __main__ -   ***** Running evaluation *****\n",
            "07/01/2020 11:28:54 - INFO - __main__ -     Num examples = 1063\n",
            "07/01/2020 11:28:54 - INFO - __main__ -     Batch size = 20\n",
            "07/01/2020 11:31:10 - INFO - __main__ -   ***** Eval results *****\n",
            "07/01/2020 11:31:10 - INFO - __main__ -     eval_accuracy = 0.8720601852054543\n",
            "07/01/2020 11:31:10 - INFO - __main__ -     eval_loss = 0.37137557235029006\n",
            "07/01/2020 11:31:10 - INFO - __main__ -     roc_auc = {0: 0.5152379058694554, 'micro': 0.6318709589535352}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOnLoVXm2ruj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Fzd9oAdwu-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "outputId": "f1527e2e-4cc1-473b-d56a-2e421af56be8"
      },
      "source": [
        "print (\"training accuracy: \", model.epoch_train_accuracy)\n",
        "print (\"training loss: \", model.epoch_train_loss)\n",
        "print (\"validation accuracy: \", model.epoch_validation_accuracy)\n",
        "print (\"validation loss: \", model.epoch_validation_loss)\n",
        "\n",
        "plt.plot(range(0,len(model.epoch_validation_loss)), model.epoch_validation_loss, \"r\", label = \"Validation Loss\") \n",
        "plt.plot(range(0,len(model.epoch_train_loss)), model.epoch_train_loss, \"g\", label = \"Training Loss\") \n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss graph\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(0,len(model.epoch_validation_accuracy)), model.epoch_validation_accuracy, \"*-\", label = \"Validation Accuracy\") \n",
        "plt.plot(range(0,len(model.epoch_train_accuracy)), model.epoch_train_accuracy, \"g\", label = \"Training Accuracy\") \n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy graph\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training accuracy:  [0.4056503650871848, 0.37032570095680023]\n",
            "training loss:  [0.4056503650871848, 0.37032570095680023]\n",
            "validation accuracy:  [0.8720601852054543, 0.8720601852054543]\n",
            "validation loss:  [0.3726839318319603, 0.37137557235029006]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_ShFKz-osDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Save a trained model\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
        "output_model_file = os.path.join(\"/content/drive/My Drive/DL_Project/BERT_Trained_Model\", \"finetuned_Bert_tweet_model.bin\")\n",
        "torch.save(model_to_save.state_dict(), output_model_file)\n",
        "\n",
        "# # Load a trained model that you have fine-tuned\n",
        "# model_state_dict = torch.load(output_model_file)\n",
        "# model = BertForMultiLabelSequenceClassification.from_pretrained(args['bert_model'], num_labels = num_labels, state_dict=model_state_dict)\n",
        "# model.to(device)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0irnMoRbosDp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f7bbacaa-f93d-484f-bea0-73e06ffc5e38"
      },
      "source": [
        "model"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMultiLabelSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lkwvslO0PQIG",
        "colab": {}
      },
      "source": [
        "def predict(model, path, test_filename='test.csv'):\n",
        "    predict_processor = MultiLabelTextProcessor(path)\n",
        "    test_examples = predict_processor.get_test_examples(path, test_filename, size=-1)\n",
        "    \n",
        "    # Hold input data for returning it \n",
        "    input_data = [{ 'id': input_example.guid, 'comment_text': input_example.text_a } for input_example in test_examples]\n",
        "\n",
        "    test_features = convert_examples_to_features(\n",
        "        test_examples, label_list, args['max_seq_length'], tokenizer)\n",
        "    \n",
        "    \n",
        "\n",
        "    logger.info(\"***** Running prediction *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(test_examples))\n",
        "    logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n",
        "\n",
        "\n",
        "    all_input_ids = torch.tensor([f.input_ids for f in test_features], dtype=torch.long)\n",
        "    all_input_mask = torch.tensor([f.input_mask for f in test_features], dtype=torch.long)\n",
        "    all_segment_ids = torch.tensor([f.segment_ids for f in test_features], dtype=torch.long)\n",
        "    all_labels_ids = torch.tensor([f.label_ids for f in test_features], dtype=torch.float)\n",
        "    print (all_input_ids.shape, all_input_mask.shape, all_segment_ids.shape, all_labels_ids.shape)\n",
        "    test_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_labels_ids)\n",
        "    \n",
        "    # Run prediction for full data\n",
        "    test_sampler = SequentialSampler(test_data)\n",
        "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=args['eval_batch_size'])\n",
        "    \n",
        "    all_logits = None\n",
        "    all_labels = None\n",
        "    test_loss  = 0\n",
        "    model.eval()\n",
        "    test_loss, test_accuracy = 0, 0\n",
        "    nb_test_steps, nb_test_examples = 0, 0\n",
        "\n",
        "    for step, batch in enumerate(tqdm(test_dataloader, desc=\"Prediction Iteration\")):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        input_ids, input_mask, segment_ids, label_ids = batch\n",
        "        \n",
        "        \n",
        "        with torch.no_grad():\n",
        "            loss, pred_logits = model(input_ids, segment_ids, input_mask, label_ids)\n",
        "\n",
        "            logits = model(input_ids, segment_ids, input_mask)\n",
        "        tmp_test_accuracy = accuracy_thresh(logits, label_ids)\n",
        "\n",
        "        logits = logits.sigmoid()\n",
        "\n",
        "        if all_logits is None:\n",
        "            all_logits = logits.detach().cpu().numpy()\n",
        "        else:\n",
        "            all_logits = np.concatenate((all_logits, logits.detach().cpu().numpy()), axis=0)\n",
        "           \n",
        "        \n",
        "        test_loss += loss.item()\n",
        "        nb_test_examples += input_ids.size(0)\n",
        "        nb_test_steps += 1\n",
        "        test_accuracy += tmp_test_accuracy\n",
        "        \n",
        "        res, precision, recall = fbeta(logits, label_ids) \n",
        "        \n",
        "        model.test_batch_true.append(label_ids)\n",
        "        model.test_batch_predicted.append(logits)\n",
        "        model.test_batch_precision.append(precision)\n",
        "        model.test_batch_recall.append(recall)\n",
        "\n",
        "\n",
        "        if n_gpu > 1:\n",
        "            loss = loss.mean() # mean() to average on multi-gpu.\n",
        "        if args['gradient_accumulation_steps'] > 1:\n",
        "            loss = loss / args['gradient_accumulation_steps']\n",
        "\n",
        "  \n",
        "    model.test_accuracy = test_accuracy/ nb_test_examples\n",
        "    model.test_loss = test_loss / nb_test_steps\n",
        "    model.epoch_test_loss.append(test_loss / nb_test_steps) \n",
        "    model.epoch_test_accuracy.append(test_accuracy/ nb_test_examples) \n",
        "\n",
        " \n",
        "\n",
        "    return pd.merge(pd.DataFrame(input_data), pd.DataFrame(all_logits, columns=label_list), left_index=True, right_index=True)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9MbZICtosDv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183,
          "referenced_widgets": [
            "518cd5e264904bd48e89a97472925e84",
            "987a1b76fe5c46fba46c1f5dfaa88879",
            "16edefa6346b484dabdf081e7afd64a6",
            "783a89c555a24d26849a9799eccedb64",
            "adda65a8630d41b7a4c4821652356f76",
            "6bcae39b2be143709d565ffd7b6f5bec",
            "74f9a6306dc84f63ada759954d14b774",
            "c3c238eaf4e64e16867484f194ea3e2e"
          ]
        },
        "outputId": "1a1839e3-b3dc-4308-ff85-ad953356d133"
      },
      "source": [
        "result = predict(model, DATA_PATH)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root Directory  /content/drive/My Drive/DL_Project/Tweets_Data/Corona_virus_Tweets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "07/01/2020 12:58:11 - INFO - __main__ -   ***** Running prediction *****\n",
            "07/01/2020 12:58:11 - INFO - __main__ -     Num examples = 1084\n",
            "07/01/2020 12:58:11 - INFO - __main__ -     Batch size = 20\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1084, 512]) torch.Size([1084, 512]) torch.Size([1084, 512]) torch.Size([1084, 11])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "518cd5e264904bd48e89a97472925e84",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Prediction Iteration', max=55.0, style=ProgressStyle(desc…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKIx-lCeK-MH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a565f68f-e64e-4a1b-b99a-2457da6f61ec"
      },
      "source": [
        "print (\"Test Loss\", model.test_loss)\n",
        "print (\"Test Accuracy\", model.test_accuracy)\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss 0.37745534669269215\n",
            "Test Accuracy 0.870764823417382\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr91Au4rosD0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "outputId": "77dc682d-6f04-46e0-8aca-db2661d89549"
      },
      "source": [
        "result"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>(anger,)</th>\n",
              "      <th>(anticipation,)</th>\n",
              "      <th>(disgust,)</th>\n",
              "      <th>(fear,)</th>\n",
              "      <th>(joy,)</th>\n",
              "      <th>(love,)</th>\n",
              "      <th>(optimism,)</th>\n",
              "      <th>(pessimism,)</th>\n",
              "      <th>(sadness,)</th>\n",
              "      <th>(surprise,)</th>\n",
              "      <th>(trust,)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2175</td>\n",
              "      <td>have seeing thoughtful messages young children...</td>\n",
              "      <td>0.199069</td>\n",
              "      <td>0.162531</td>\n",
              "      <td>0.184904</td>\n",
              "      <td>0.147296</td>\n",
              "      <td>0.084481</td>\n",
              "      <td>0.068057</td>\n",
              "      <td>0.151060</td>\n",
              "      <td>0.075455</td>\n",
              "      <td>0.164429</td>\n",
              "      <td>0.109937</td>\n",
              "      <td>0.065045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4135</td>\n",
              "      <td>lmaoooo said u+0001f62c u+0001f62e</td>\n",
              "      <td>0.196690</td>\n",
              "      <td>0.158654</td>\n",
              "      <td>0.181182</td>\n",
              "      <td>0.140451</td>\n",
              "      <td>0.082032</td>\n",
              "      <td>0.066272</td>\n",
              "      <td>0.146991</td>\n",
              "      <td>0.074386</td>\n",
              "      <td>0.162014</td>\n",
              "      <td>0.107597</td>\n",
              "      <td>0.062526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5615</td>\n",
              "      <td>national criminal zulfi bukhari arrested asked...</td>\n",
              "      <td>0.198127</td>\n",
              "      <td>0.160746</td>\n",
              "      <td>0.184456</td>\n",
              "      <td>0.144041</td>\n",
              "      <td>0.083156</td>\n",
              "      <td>0.067453</td>\n",
              "      <td>0.149207</td>\n",
              "      <td>0.075115</td>\n",
              "      <td>0.164220</td>\n",
              "      <td>0.109353</td>\n",
              "      <td>0.064484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4474</td>\n",
              "      <td>in honor corona stopping clinicals last time w...</td>\n",
              "      <td>0.197286</td>\n",
              "      <td>0.159760</td>\n",
              "      <td>0.182301</td>\n",
              "      <td>0.142365</td>\n",
              "      <td>0.082558</td>\n",
              "      <td>0.066715</td>\n",
              "      <td>0.148101</td>\n",
              "      <td>0.074633</td>\n",
              "      <td>0.162953</td>\n",
              "      <td>0.108234</td>\n",
              "      <td>0.063114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>268</td>\n",
              "      <td>we sick corona ca n t shit us</td>\n",
              "      <td>0.196800</td>\n",
              "      <td>0.157097</td>\n",
              "      <td>0.179399</td>\n",
              "      <td>0.137388</td>\n",
              "      <td>0.081058</td>\n",
              "      <td>0.065403</td>\n",
              "      <td>0.145421</td>\n",
              "      <td>0.073917</td>\n",
              "      <td>0.161561</td>\n",
              "      <td>0.106607</td>\n",
              "      <td>0.060661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1079</th>\n",
              "      <td>1857</td>\n",
              "      <td>easy sit home gorge carbohydrates amp abuse co...</td>\n",
              "      <td>0.200008</td>\n",
              "      <td>0.163461</td>\n",
              "      <td>0.186036</td>\n",
              "      <td>0.147600</td>\n",
              "      <td>0.084340</td>\n",
              "      <td>0.068344</td>\n",
              "      <td>0.151415</td>\n",
              "      <td>0.075524</td>\n",
              "      <td>0.165091</td>\n",
              "      <td>0.110654</td>\n",
              "      <td>0.065758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1080</th>\n",
              "      <td>2333</td>\n",
              "      <td>kucheey ghettoradio895 majimajikenya the first...</td>\n",
              "      <td>0.196799</td>\n",
              "      <td>0.158610</td>\n",
              "      <td>0.181231</td>\n",
              "      <td>0.140242</td>\n",
              "      <td>0.081771</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>0.146914</td>\n",
              "      <td>0.074079</td>\n",
              "      <td>0.162202</td>\n",
              "      <td>0.107517</td>\n",
              "      <td>0.061981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1081</th>\n",
              "      <td>5978</td>\n",
              "      <td>suicide vest kaboom ola-u-ukber attacks last ~...</td>\n",
              "      <td>0.199023</td>\n",
              "      <td>0.161991</td>\n",
              "      <td>0.184459</td>\n",
              "      <td>0.146525</td>\n",
              "      <td>0.083801</td>\n",
              "      <td>0.067452</td>\n",
              "      <td>0.150388</td>\n",
              "      <td>0.075132</td>\n",
              "      <td>0.163337</td>\n",
              "      <td>0.109784</td>\n",
              "      <td>0.065005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1082</th>\n",
              "      <td>215</td>\n",
              "      <td>here we go   adam schiff announces legislation...</td>\n",
              "      <td>0.199735</td>\n",
              "      <td>0.163677</td>\n",
              "      <td>0.186823</td>\n",
              "      <td>0.148581</td>\n",
              "      <td>0.084754</td>\n",
              "      <td>0.068676</td>\n",
              "      <td>0.151407</td>\n",
              "      <td>0.076038</td>\n",
              "      <td>0.164801</td>\n",
              "      <td>0.110938</td>\n",
              "      <td>0.066326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1083</th>\n",
              "      <td>3322</td>\n",
              "      <td>iitguwahati contributing various levels fight ...</td>\n",
              "      <td>0.197802</td>\n",
              "      <td>0.160742</td>\n",
              "      <td>0.183609</td>\n",
              "      <td>0.143994</td>\n",
              "      <td>0.083234</td>\n",
              "      <td>0.067456</td>\n",
              "      <td>0.148877</td>\n",
              "      <td>0.075006</td>\n",
              "      <td>0.163190</td>\n",
              "      <td>0.109101</td>\n",
              "      <td>0.064191</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1084 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...  (trust,)\n",
              "0     2175  ...  0.065045\n",
              "1     4135  ...  0.062526\n",
              "2     5615  ...  0.064484\n",
              "3     4474  ...  0.063114\n",
              "4      268  ...  0.060661\n",
              "...    ...  ...       ...\n",
              "1079  1857  ...  0.065758\n",
              "1080  2333  ...  0.061981\n",
              "1081  5978  ...  0.065005\n",
              "1082   215  ...  0.066326\n",
              "1083  3322  ...  0.064191\n",
              "\n",
              "[1084 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gitKx28LH7io",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class OUTPUT_MultiLabelTextProcessor(DataProcessor):\n",
        "    \n",
        "    def __init__(self, data_dir):\n",
        "        self.data_dir = data_dir\n",
        "        self.labels = None\n",
        "        print (\"root Directory \", self.data_dir)\n",
        "    \n",
        "    def get_test_examples(self, data_dir, data_file_name, size=-1):\n",
        "        data_df = pd.read_csv(os.path.join(data_dir, data_file_name))\n",
        "#         data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
        "        if size == -1:\n",
        "            return self._create_examples(data_df, \"test\")\n",
        "        else:\n",
        "            return self._create_examples(data_df.sample(size), \"test\")\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        if self.labels == None:\n",
        "            self.labels = list(pd.read_csv(os.path.join(self.data_dir, \"classes.txt\"),header=None, sep = '\\t').values)\n",
        "        return self.labels\n",
        "\n",
        "    def _create_examples(self, df, set_type, labels_available=False):\n",
        "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "        examples = []\n",
        "        for (i, row) in enumerate(df.values):\n",
        "            guid = row[2]\n",
        "            text_a = str(row[4])\n",
        "            if labels_available:\n",
        "                labels = row[13:]\n",
        "            else:\n",
        "                labels = []\n",
        "            examples.append(\n",
        "                InputExample(guid=guid, text_a=text_a, labels=labels))\n",
        "        return examples\n",
        "        "
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU8W1RrN_sSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label(model, path, test_filename='Tweets_Final_Dataset.csv'):\n",
        "    predict_processor = OUTPUT_MultiLabelTextProcessor(path)\n",
        "    test_examples = predict_processor.get_test_examples(path, test_filename, size=-1)\n",
        "    \n",
        "    # Hold input data for returning it \n",
        "    input_data = pd.read_csv(os.path.join(path, test_filename))\n",
        "\n",
        "    test_features = convert_examples_to_features(\n",
        "        test_examples, label_list, args['max_seq_length'], tokenizer)\n",
        "    \n",
        "    logger.info(\"***** Running prediction *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(test_examples))\n",
        "    logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n",
        "    \n",
        "    all_input_ids = torch.tensor([f.input_ids for f in test_features], dtype=torch.long)\n",
        "    all_input_mask = torch.tensor([f.input_mask for f in test_features], dtype=torch.long)\n",
        "    all_segment_ids = torch.tensor([f.segment_ids for f in test_features], dtype=torch.long)\n",
        "\n",
        "    test_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids)\n",
        "    \n",
        "    # Run prediction for full data\n",
        "    test_sampler = SequentialSampler(test_data)\n",
        "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=args['eval_batch_size'])\n",
        "    \n",
        "    all_logits = None\n",
        "    \n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    for step, batch in enumerate(tqdm(test_dataloader, desc=\"Emotion Labeling Iteration\")):\n",
        "        input_ids, input_mask, segment_ids = batch\n",
        "        input_ids = input_ids.to(device)\n",
        "        input_mask = input_mask.to(device)\n",
        "        segment_ids = segment_ids.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            logits = model(input_ids, segment_ids, input_mask)\n",
        "            logits = logits.sigmoid()\n",
        "\n",
        "        if all_logits is None:\n",
        "            all_logits = logits.detach().cpu().numpy()\n",
        "        else:\n",
        "            all_logits = np.concatenate((all_logits, logits.detach().cpu().numpy()), axis=0)\n",
        "            \n",
        "        \n",
        "       \n",
        "        nb_eval_examples += input_ids.size(0)\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    return pd.merge(pd.DataFrame(input_data), pd.DataFrame(all_logits, columns=label_list), left_index=True, right_index=True)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cyl9PA2EXLbX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166,
          "referenced_widgets": [
            "1fd6d0e23c2f40718919f4e818d9bc4b",
            "676135e6218a4fd988ff3f923cd3e7cc",
            "32c113c958bf478aba13f9b05e515e5e",
            "10cc2afee1b5438da6bbec4449d6c9fb",
            "3050f53c255f4630b485cf77e9e3e335",
            "633f4077addf491dae8e227f74af3ce9",
            "a19b586ac609489fba1caccd4b07fde0",
            "a290488ad49f45f79caf755672cebadc"
          ]
        },
        "outputId": "f19b194a-4648-4bb6-e0be-0f821b7c2fea"
      },
      "source": [
        "labeled_result = label(model, DATA_PATH)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root Directory  /content/drive/My Drive/Tweets_Data/Corona_virus_Tweets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "06/30/2020 19:43:01 - INFO - __main__ -   ***** Running prediction *****\n",
            "06/30/2020 19:43:01 - INFO - __main__ -     Num examples = 290044\n",
            "06/30/2020 19:43:01 - INFO - __main__ -     Batch size = 20\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fd6d0e23c2f40718919f4e818d9bc4b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Emotion Labeling Iteration', max=14503.0, style=ProgressS…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWpzLFoARiNg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "outputId": "9a673d5b-3adb-4cb5-8d75-945d50a15d49"
      },
      "source": [
        "labeled_result"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>status_id</th>\n",
              "      <th>date</th>\n",
              "      <th>time</th>\n",
              "      <th>text</th>\n",
              "      <th>is_quote</th>\n",
              "      <th>display_text_width</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>symbols</th>\n",
              "      <th>lang</th>\n",
              "      <th>location</th>\n",
              "      <th>(anger,)</th>\n",
              "      <th>(anticipation,)</th>\n",
              "      <th>(disgust,)</th>\n",
              "      <th>(fear,)</th>\n",
              "      <th>(joy,)</th>\n",
              "      <th>(love,)</th>\n",
              "      <th>(optimism,)</th>\n",
              "      <th>(pessimism,)</th>\n",
              "      <th>(sadness,)</th>\n",
              "      <th>(surprise,)</th>\n",
              "      <th>(trust,)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.033000e+03</td>\n",
              "      <td>1240853506904305664</td>\n",
              "      <td>2020-03-20</td>\n",
              "      <td>04:11:44</td>\n",
              "      <td>full details seen confusion</td>\n",
              "      <td>False</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>Los Angeles, CA</td>\n",
              "      <td>0.195776</td>\n",
              "      <td>0.158252</td>\n",
              "      <td>0.180665</td>\n",
              "      <td>0.140057</td>\n",
              "      <td>0.081424</td>\n",
              "      <td>0.066484</td>\n",
              "      <td>0.145732</td>\n",
              "      <td>0.074379</td>\n",
              "      <td>0.162791</td>\n",
              "      <td>0.106904</td>\n",
              "      <td>0.061287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.081000e+03</td>\n",
              "      <td>1241544587186827264</td>\n",
              "      <td>2020-03-22</td>\n",
              "      <td>01:57:51</td>\n",
              "      <td>n already seen two *excellent* simulation-base...</td>\n",
              "      <td>False</td>\n",
              "      <td>140</td>\n",
              "      <td>0</td>\n",
              "      <td>132</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.197192</td>\n",
              "      <td>0.160486</td>\n",
              "      <td>0.181407</td>\n",
              "      <td>0.142545</td>\n",
              "      <td>0.082456</td>\n",
              "      <td>0.067463</td>\n",
              "      <td>0.147679</td>\n",
              "      <td>0.074904</td>\n",
              "      <td>0.162970</td>\n",
              "      <td>0.108366</td>\n",
              "      <td>0.063363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.688000e+03</td>\n",
              "      <td>1243057868615475200</td>\n",
              "      <td>2020-03-26</td>\n",
              "      <td>06:11:05</td>\n",
              "      <td>let go things control focus things *can* control</td>\n",
              "      <td>True</td>\n",
              "      <td>159</td>\n",
              "      <td>344</td>\n",
              "      <td>142</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>Silicon Valley</td>\n",
              "      <td>0.196804</td>\n",
              "      <td>0.159230</td>\n",
              "      <td>0.181661</td>\n",
              "      <td>0.141630</td>\n",
              "      <td>0.082064</td>\n",
              "      <td>0.066976</td>\n",
              "      <td>0.146665</td>\n",
              "      <td>0.074710</td>\n",
              "      <td>0.163263</td>\n",
              "      <td>0.107689</td>\n",
              "      <td>0.062420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.336000e+03</td>\n",
              "      <td>1244834112596303872</td>\n",
              "      <td>2020-03-31</td>\n",
              "      <td>03:49:14</td>\n",
              "      <td>bihar man beaten death 2 people returned mahar...</td>\n",
              "      <td>False</td>\n",
              "      <td>144</td>\n",
              "      <td>0</td>\n",
              "      <td>1084</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>Republic of India</td>\n",
              "      <td>0.198484</td>\n",
              "      <td>0.161242</td>\n",
              "      <td>0.184087</td>\n",
              "      <td>0.144222</td>\n",
              "      <td>0.083068</td>\n",
              "      <td>0.068169</td>\n",
              "      <td>0.148992</td>\n",
              "      <td>0.075642</td>\n",
              "      <td>0.164874</td>\n",
              "      <td>0.109094</td>\n",
              "      <td>0.064662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.904000e+03</td>\n",
              "      <td>1243069931056398336</td>\n",
              "      <td>2020-03-26</td>\n",
              "      <td>06:59:01</td>\n",
              "      <td>u+0001f4f7 corona virus exists u+0001f922 u+00...</td>\n",
              "      <td>False</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>Portland, OR</td>\n",
              "      <td>0.197295</td>\n",
              "      <td>0.159757</td>\n",
              "      <td>0.182838</td>\n",
              "      <td>0.141956</td>\n",
              "      <td>0.082365</td>\n",
              "      <td>0.067379</td>\n",
              "      <td>0.147726</td>\n",
              "      <td>0.075150</td>\n",
              "      <td>0.164023</td>\n",
              "      <td>0.108625</td>\n",
              "      <td>0.063791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290039</th>\n",
              "      <td>1.245977e+18</td>\n",
              "      <td>1245979247933419520</td>\n",
              "      <td>2020-04-03</td>\n",
              "      <td>07:39:36</td>\n",
              "      <td>duty saving nation corona</td>\n",
              "      <td>False</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.194911</td>\n",
              "      <td>0.156843</td>\n",
              "      <td>0.179707</td>\n",
              "      <td>0.138002</td>\n",
              "      <td>0.080950</td>\n",
              "      <td>0.065322</td>\n",
              "      <td>0.144498</td>\n",
              "      <td>0.073656</td>\n",
              "      <td>0.162364</td>\n",
              "      <td>0.105980</td>\n",
              "      <td>0.059516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290040</th>\n",
              "      <td>1.245978e+18</td>\n",
              "      <td>1245980267845685248</td>\n",
              "      <td>2020-04-03</td>\n",
              "      <td>07:43:39</td>\n",
              "      <td>jerotichseii good morning young lady sells mbo...</td>\n",
              "      <td>False</td>\n",
              "      <td>241</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.198547</td>\n",
              "      <td>0.161142</td>\n",
              "      <td>0.184122</td>\n",
              "      <td>0.144265</td>\n",
              "      <td>0.082963</td>\n",
              "      <td>0.068181</td>\n",
              "      <td>0.149191</td>\n",
              "      <td>0.075638</td>\n",
              "      <td>0.164718</td>\n",
              "      <td>0.109454</td>\n",
              "      <td>0.065120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290041</th>\n",
              "      <td>1.245980e+18</td>\n",
              "      <td>1245980923641753600</td>\n",
              "      <td>2020-04-03</td>\n",
              "      <td>07:46:16</td>\n",
              "      <td>zeenewshindi corona fighter get justice</td>\n",
              "      <td>False</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>zeenewshindi</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.194528</td>\n",
              "      <td>0.156274</td>\n",
              "      <td>0.179180</td>\n",
              "      <td>0.137243</td>\n",
              "      <td>0.080582</td>\n",
              "      <td>0.065102</td>\n",
              "      <td>0.144129</td>\n",
              "      <td>0.073349</td>\n",
              "      <td>0.161737</td>\n",
              "      <td>0.105780</td>\n",
              "      <td>0.059484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290042</th>\n",
              "      <td>1.245980e+18</td>\n",
              "      <td>1245980751889346560</td>\n",
              "      <td>2020-04-03</td>\n",
              "      <td>07:45:35</td>\n",
              "      <td>hold watching drama long time ago thinking cat...</td>\n",
              "      <td>False</td>\n",
              "      <td>139</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>Turkey</td>\n",
              "      <td>0.200004</td>\n",
              "      <td>0.162933</td>\n",
              "      <td>0.185989</td>\n",
              "      <td>0.146552</td>\n",
              "      <td>0.083807</td>\n",
              "      <td>0.069203</td>\n",
              "      <td>0.151033</td>\n",
              "      <td>0.076389</td>\n",
              "      <td>0.165846</td>\n",
              "      <td>0.110770</td>\n",
              "      <td>0.067048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290043</th>\n",
              "      <td>1.245980e+18</td>\n",
              "      <td>1245982142305165312</td>\n",
              "      <td>2020-04-03</td>\n",
              "      <td>07:51:06</td>\n",
              "      <td>sir situation happening near ration shops tela...</td>\n",
              "      <td>False</td>\n",
              "      <td>150</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.197901</td>\n",
              "      <td>0.160199</td>\n",
              "      <td>0.182570</td>\n",
              "      <td>0.142218</td>\n",
              "      <td>0.082131</td>\n",
              "      <td>0.067485</td>\n",
              "      <td>0.148342</td>\n",
              "      <td>0.074884</td>\n",
              "      <td>0.163443</td>\n",
              "      <td>0.108701</td>\n",
              "      <td>0.063931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>290044 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             user_id            status_id  ... (surprise,)  (trust,)\n",
              "0       1.033000e+03  1240853506904305664  ...    0.106904  0.061287\n",
              "1       1.081000e+03  1241544587186827264  ...    0.108366  0.063363\n",
              "2       1.688000e+03  1243057868615475200  ...    0.107689  0.062420\n",
              "3       3.336000e+03  1244834112596303872  ...    0.109094  0.064662\n",
              "4       4.904000e+03  1243069931056398336  ...    0.108625  0.063791\n",
              "...              ...                  ...  ...         ...       ...\n",
              "290039  1.245977e+18  1245979247933419520  ...    0.105980  0.059516\n",
              "290040  1.245978e+18  1245980267845685248  ...    0.109454  0.065120\n",
              "290041  1.245980e+18  1245980923641753600  ...    0.105780  0.059484\n",
              "290042  1.245980e+18  1245980751889346560  ...    0.110770  0.067048\n",
              "290043  1.245980e+18  1245982142305165312  ...    0.108701  0.063931\n",
              "\n",
              "[290044 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPZx3qOWRapw",
        "colab_type": "text"
      },
      "source": [
        "Save Model output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOkpPlapPCVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labeled_result.to_csv(\"/content/drive/My Drive/DL_Project/Tweets_Data/Corona_virus_Tweets/BERT_MODEL_OUTPUT_SemEvalTrained.csv\", index = False )"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BsOid3EEb8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}