{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Multi-label Text Classification using BERT – The Mighty Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cd308b3bd4134ba99b7d868b4deaef43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_08b33e92af7f4581831699c4cf6631e1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_90dc5723a3a64a3aa019243661af1d76",
              "IPY_MODEL_e3878d1e644f459fb54a8ea88727b30a"
            ]
          }
        },
        "08b33e92af7f4581831699c4cf6631e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90dc5723a3a64a3aa019243661af1d76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9f2c3288f8cd4c2694c3aa15a2870d48",
            "_dom_classes": [],
            "description": "Epoch: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb226757053342ff8812f57e5672eb7f"
          }
        },
        "e3878d1e644f459fb54a8ea88727b30a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bbce93acaa7b42ffaf4154d6e0f0f1fe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [33:50&lt;00:00, 1015.45s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9cd9c9525d343d196bdfb2263e08c6a"
          }
        },
        "9f2c3288f8cd4c2694c3aa15a2870d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb226757053342ff8812f57e5672eb7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bbce93acaa7b42ffaf4154d6e0f0f1fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9cd9c9525d343d196bdfb2263e08c6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a8c96ea0f924c308ebb4791f2f54b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ec21b943c7394795bf1e3c19b5ae0c9b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_35ac0b5193ef40a9923dea0ad4feb6de",
              "IPY_MODEL_21f5f0af84774fbca3cdc0a314a58774"
            ]
          }
        },
        "ec21b943c7394795bf1e3c19b5ae0c9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35ac0b5193ef40a9923dea0ad4feb6de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a61629823b2747258c78fef84ce2159a",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 342,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 342,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f367454ee9846f8b2930cd1504e05ce"
          }
        },
        "21f5f0af84774fbca3cdc0a314a58774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1ea1c71dba304112a854e9436c1cd89b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 342/342 [33:50&lt;00:00,  5.94s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e72fd669e28b466a8cff7d51086caacb"
          }
        },
        "a61629823b2747258c78fef84ce2159a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f367454ee9846f8b2930cd1504e05ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ea1c71dba304112a854e9436c1cd89b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e72fd669e28b466a8cff7d51086caacb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1633de3b792641afb740b18a36ef93fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0d25d5cd3d0b48e6b2c2db004d24c95b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_856bca33d68141b484c560fe53f199e9",
              "IPY_MODEL_24365822fab84deb8e025629e5e8ab12"
            ]
          }
        },
        "0d25d5cd3d0b48e6b2c2db004d24c95b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "856bca33d68141b484c560fe53f199e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_90792c15090b4df69b56acc1851041e9",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 342,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 342,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6fe061d1269b48649e1e38e90ddfca88"
          }
        },
        "24365822fab84deb8e025629e5e8ab12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aaefbec08ebb4642b2c77063370e0d5c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 342/342 [16:41&lt;00:00,  2.93s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b03ffeb71a04a08a684b76de011713c"
          }
        },
        "90792c15090b4df69b56acc1851041e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6fe061d1269b48649e1e38e90ddfca88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aaefbec08ebb4642b2c77063370e0d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b03ffeb71a04a08a684b76de011713c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6fe1b2a84384404a4612704042740bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d1e39126cbd14a87b1f2216eb99ba4ba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_72ff0b3da31c4fd1919a3a7eb9871a9b",
              "IPY_MODEL_a9c920a672ea488d9c21d52351c74ef8"
            ]
          }
        },
        "d1e39126cbd14a87b1f2216eb99ba4ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72ff0b3da31c4fd1919a3a7eb9871a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fd2324baeb654ebf8b4a3aeb80896813",
            "_dom_classes": [],
            "description": "Prediction Iteration: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 163,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 163,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ab1c473af714a09b8513a92a1939fd1"
          }
        },
        "a9c920a672ea488d9c21d52351c74ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_259c351bb9fd423ab408f530fdabd73e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 163/163 [06:58&lt;00:00,  2.57s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_643aa935801d49ebb970ba3365d47078"
          }
        },
        "fd2324baeb654ebf8b4a3aeb80896813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ab1c473af714a09b8513a92a1939fd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "259c351bb9fd423ab408f530fdabd73e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "643aa935801d49ebb970ba3365d47078": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6BbeLSbo4xF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "879f638e-52f9-46d5-ffa6-ea25f3ec25b5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwImqsKWo_VF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c99344d2-2b79-4288-d2b3-6535098f84e9"
      },
      "source": [
        "!pip install pytorch-pretrained-bert\n",
        "!pip install transformers\n",
        "!pip install fastai"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 21.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.5)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.5.1+cu101)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.14.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.16.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.9 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.17.9)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.9->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.9->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 14.5MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers==0.8.0-rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/bd/e5abec46af977c8a1375c1dca7cb1e5b3ec392ef279067af7f6bc50491a0/tokenizers-0.8.0rc4-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 29.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=12d5f26ebe3919a53146d1e6964ce1122a001e003fcfa7e52caee1610f81f257\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.0rc4 transformers-3.0.0\n",
            "Requirement already satisfied: fastai in /usr/local/lib/python3.6/dist-packages (1.0.61)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastai) (0.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (1.0.5)\n",
            "Requirement already satisfied: fastprogress>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from fastai) (0.2.3)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.6/dist-packages (from fastai) (1.3.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.23.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai) (0.6.1+cu101)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (3.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai) (20.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.4.1)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from fastai) (7.352.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from fastai) (4.6.3)\n",
            "Requirement already satisfied: spacy>=2.0.18; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from fastai) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.18.5)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from fastai) (2.7.1)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.5.1+cu101)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (1.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->fastai) (1.12.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (2.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (4.41.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.7.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (3.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (47.3.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (7.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->fastai) (0.16.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teuXVsiDI12Q",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMXYP9pgosCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_pretrained_bert.tokenization import BertTokenizer, WordpieceTokenizer\n",
        "from pytorch_pretrained_bert.modeling import BertForPreTraining, BertPreTrainedModel, BertConfig, BertForMaskedLM\n",
        "from transformers import BertForSequenceClassification, BertModel \n",
        "\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import re\n",
        "from torch import Tensor\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "import torch.nn as nn\n",
        "from fastai.text import Tokenizer, Vocab\n",
        "import pandas as pd\n",
        "import collections\n",
        "import os\n",
        "import pdb\n",
        "from tqdm import tqdm, trange\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "# Installing Nvidia Apex\n",
        "# os.system('git clone https://github.com/NVIDIA/apex; cd apex; pip install -v --no-cache-dir' + \n",
        "#         ' --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./')\n",
        "# os.system('rm -rf apex/.git') # too many files, Kaggle fails\n",
        "\n",
        "import apex\n",
        "from sklearn.model_selection import train_test_split\n",
        "module_path = os.path.abspath(os.path.join('..'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from pytorch_pretrained_bert.optimization import BertAdam\n",
        "\n",
        "from sklearn.metrics import accuracy_score, jaccard_similarity_score, classification_report, precision_score, recall_score, f1_score\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
        "                    level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2MBEKCwosCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_PATH=Path('/content/drive/My Drive/Deep Leaning Project - COVID 19 Tweets Analysis/Tweets Data/')\n",
        "\n",
        "# DATA_PATH.mkdir(exist_ok=True)\n",
        "\n",
        "PATH=Path('/content/drive/My Drive/Deep Leaning Project - COVID 19 Tweets Analysis/Tweets Data/')\n",
        "PATH.mkdir(exist_ok=True)\n",
        "\n",
        "CLAS_DATA_PATH=PATH/'class'\n",
        "# CLAS_DATA_PATH.mkdir(exist_ok=True)\n",
        "\n",
        "model_state_dict = None\n",
        "\n",
        "# BERT_PRETRAINED_PATH = Path('../trained_model/')\n",
        "BERT_PRETRAINED_PATH = Path('/content/drive/My Drive/Deep Leaning Project - COVID 19 Tweets Analysis/uncased_L-12_H-768_A-12/')\n",
        "# BERT_PRETRAINED_PATH = Path('../../complaints/bert/pretrained-weights/cased_L-12_H-768_A-12/')\n",
        "# BERT_PRETRAINED_PATH = Path('../../complaints/bert/pretrained-weights/uncased_L-24_H-1024_A-16/')\n",
        "\n",
        "\n",
        "# BERT_FINETUNED_WEIGHTS = Path('../trained_model/toxic_comments')\n",
        "\n",
        "PYTORCH_PRETRAINED_BERT_CACHE = BERT_PRETRAINED_PATH/'cache/'\n",
        "PYTORCH_PRETRAINED_BERT_CACHE.mkdir(exist_ok=True)\n",
        "\n",
        "# output_model_file = os.path.join(BERT_FINETUNED_WEIGHTS, \"pytorch_model.bin\")\n",
        "\n",
        "# Load a trained model that you have fine-tuned\n",
        "# model_state_dict = torch.load(output_model_file)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmPmrEgOosCf",
        "colab_type": "text"
      },
      "source": [
        "### Model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28TS92ctosCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = {\n",
        "    \"train_size\": -1,\n",
        "    \"val_size\": -1,\n",
        "    \"full_data_dir\": DATA_PATH,\n",
        "    \"data_dir\": PATH,\n",
        "    \"task_name\": \"toxic_multilabel\",\n",
        "    \"no_cuda\": False,\n",
        "    \"bert_model\": BERT_PRETRAINED_PATH,\n",
        "    \"output_dir\": CLAS_DATA_PATH/'output',\n",
        "    \"max_seq_length\": 512,\n",
        "    \"do_train\": True,\n",
        "    \"do_eval\": True,\n",
        "    \"do_lower_case\": True,\n",
        "    \"train_batch_size\": 20,\n",
        "    \"eval_batch_size\": 20,\n",
        "    \"learning_rate\": 3e-5,\n",
        "    \"num_train_epochs\": 2.0,\n",
        "    \"warmup_proportion\": 0.1,\n",
        "    \"no_cuda\": False,\n",
        "    \"local_rank\": -1,\n",
        "    \"seed\": 40,\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"optimize_on_cpu\": False,\n",
        "    \"fp16\": False,\n",
        "    \"loss_scale\": 128\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1q5CF9nosCj",
        "colab_type": "text"
      },
      "source": [
        "### Model Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeFx1e40osCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertForMultiLabelSequenceClassification(BertForSequenceClassification):\n",
        "    \"\"\"BERT model for classification.\n",
        "    This module is composed of the BERT model with a linear layer on top of\n",
        "    the pooled output.\n",
        "    Params:\n",
        "        `config`: a BertConfig class instance with the configuration to build a new model.\n",
        "        `num_labels`: the number of classes for the classifier. Default = 2.\n",
        "    Inputs:\n",
        "        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
        "            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
        "            `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
        "        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
        "            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
        "            a `sentence B` token (see BERT paper for more details).\n",
        "        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
        "            selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
        "            input sequence length in the current batch. It's the mask that we typically use for attention when\n",
        "            a batch has varying length sentences.\n",
        "        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]\n",
        "            with indices selected in [0, ..., num_labels].\n",
        "    Outputs:\n",
        "        if `labels` is not `None`:\n",
        "            Outputs the CrossEntropy classification loss of the output with the labels.\n",
        "        if `labels` is `None`:\n",
        "            Outputs the classification logits of shape [batch_size, num_labels].\n",
        "    Example usage:\n",
        "    ```python\n",
        "    # Already been converted into WordPiece token ids\n",
        "    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
        "    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
        "    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])\n",
        "    config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
        "        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
        "    num_labels = 2\n",
        "    model = BertForSequenceClassification(config, num_labels)\n",
        "    logits = model(input_ids, token_type_ids, input_mask)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    def __init__(self, config, num_labels=11):\n",
        "        super(BertForMultiLabelSequenceClassification, self).__init__(config)\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = torch.nn.Linear(config.hidden_size, num_labels)\n",
        "\n",
        "        self.epoch_train_loss = list()\n",
        "        self.epoch_train_accuracy = list()\n",
        "        \n",
        "        self.epoch_validation_loss = list()\n",
        "        self.epoch_validation_accuracy = list()\n",
        "        \n",
        "        self.epoch_test_loss = list()\n",
        "        self.epoch_test_accuracy = list()\n",
        "        self.epoch_test_precision = list()\n",
        "        self.epoch_test_recall = list()\n",
        "        \n",
        "        self.train_batch_true = list()\n",
        "        self.train_batch_predicted = list()\n",
        "        self.train_batch_precision = list()\n",
        "        self.train_batch_recall = list()\n",
        "\n",
        "        self.validation_batch_true = list()\n",
        "        self.validation_batch_predicted = list()\n",
        "        self.validation_batch_precision = list()\n",
        "        self.validation_batch_recall = list()\n",
        "        \n",
        "        self.test_batch_true = list()\n",
        "        self.test_batch_predicted = list()\n",
        "        self.test_batch_precision = list()\n",
        "        self.test_batch_recall = list()\n",
        "        \n",
        "        self.train_accuracy = 0\n",
        "        self.validation_accuracy = 0\n",
        "        self.test_accuracy = 0\n",
        "        \n",
        "        self.train_loss = 0\n",
        "        self.validation_loss = 0\n",
        "        self.test_loss = 0\n",
        "         \n",
        "        # self.apply(self.init_bert_weights)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = BCEWithLogitsLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
        "            return loss, logits\n",
        "        else:\n",
        "            return logits\n",
        "        \n",
        "\n",
        "    def get_ecoder_layers_count(self):\n",
        "      nos =0\n",
        "      for param in self.bert.parameters():\n",
        "            nos += 1\n",
        "      return nos\n",
        "\n",
        "\n",
        "    def unfreeze_bert_encoder_count(self, count):\n",
        "        i = 0\n",
        "        nos = self.get_ecoder_layers_count()\n",
        "        for param in self.bert.parameters():\n",
        "            i += 1\n",
        "            if i > (nos-count):\n",
        "              param.requires_grad = True\n",
        "            else:\n",
        "              param.requires_grad = False\n",
        "    \n",
        "    def freeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "    \n",
        "    def unfreeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = True"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9fdqKi9osCm",
        "colab_type": "text"
      },
      "source": [
        "### Data representation Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXQoVK0bosCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, labels=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "\n",
        "        Args:\n",
        "            guid: Unique id for the example.\n",
        "            text_a: string. The untokenized text of the first sequence. For single\n",
        "            sequence tasks, only this sequence must be specified.\n",
        "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "            Only must be specified for sequence pair tasks.\n",
        "            labels: (Optional) [string]. The label of the example. This should be\n",
        "            specified for train and dev examples, but not for test examples.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, input_mask, segment_ids, label_ids):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_ids = label_ids"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xMgFckPosCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataProcessor(object):\n",
        "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "    \n",
        "    def get_test_examples(self, data_dir, data_file_name, size=-1):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
        "        raise NotImplementedError() \n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
        "        raise NotImplementedError()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAGmGjjgosCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiLabelTextProcessor(DataProcessor):\n",
        "    \n",
        "    def __init__(self, data_dir):\n",
        "        self.data_dir = data_dir\n",
        "        self.labels = None\n",
        "        print (\"root Directory \", self.data_dir)\n",
        "    \n",
        "    def get_train_examples(self, data_dir, size=-1):\n",
        "        filename = 'train.txt'\n",
        "        logger.info(\"LOOKING AT {}\".format(os.path.join(data_dir, filename)))\n",
        "        if size == -1:\n",
        "            data_df = pd.read_csv(os.path.join(data_dir, filename), sep = '\\t')\n",
        "#             data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
        "            return self._create_examples(data_df, \"train\")\n",
        "        else:\n",
        "            data_df = pd.read_csv(os.path.join(data_dir, filename),  sep = '\\t')\n",
        "#             data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
        "            return self._create_examples(data_df.sample(size), \"train\")\n",
        "        \n",
        "    def get_dev_examples(self, data_dir, size=-1):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        filename = 'dev.txt'\n",
        "        if size == -1:\n",
        "            data_df = pd.read_csv(os.path.join(data_dir, filename), sep = '\\t')\n",
        "#             data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
        "            return self._create_examples(data_df, \"dev\")\n",
        "        else:\n",
        "            data_df = pd.read_csv(os.path.join(data_dir, filename), sep = '\\t')\n",
        "#             data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
        "            return self._create_examples(data_df.sample(size), \"dev\")\n",
        "    \n",
        "    def get_test_examples(self, data_dir, data_file_name, size=-1):\n",
        "        data_df = pd.read_csv(os.path.join(data_dir, data_file_name), sep = '\\t')\n",
        "#         data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
        "        if size == -1:\n",
        "            return self._create_examples(data_df, \"test\")\n",
        "        else:\n",
        "            return self._create_examples(data_df.sample(size), \"test\")\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        if self.labels == None:\n",
        "            self.labels = list(pd.read_csv(os.path.join(self.data_dir, \"classes.txt\"),header=None, sep = '\\t').values)\n",
        "        return self.labels\n",
        "\n",
        "    def _create_examples(self, df, set_type, labels_available=True):\n",
        "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "        examples = []\n",
        "        for (i, row) in enumerate(df.values):\n",
        "            guid = row[0]\n",
        "            text_a = row[1]\n",
        "            if labels_available:\n",
        "                labels = row[2:]\n",
        "            else:\n",
        "                labels = []\n",
        "            examples.append(\n",
        "                InputExample(guid=guid, text_a=text_a, labels=labels))\n",
        "        return examples\n",
        "        "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rzqp-TaZosCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer):\n",
        "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
        "\n",
        "#     label_map = {label : i for i, label in enumerate(label_list)}\n",
        "\n",
        "    features = []\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        tokens_a = tokenizer.tokenize(example.text_a)\n",
        "\n",
        "        tokens_b = None\n",
        "        if example.text_b:\n",
        "            tokens_b = tokenizer.tokenize(example.text_b)\n",
        "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "            # length is less than the specified length.\n",
        "            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
        "        else:\n",
        "            # Account for [CLS] and [SEP] with \"- 2\"\n",
        "            if len(tokens_a) > max_seq_length - 2:\n",
        "                tokens_a = tokens_a[:(max_seq_length - 2)]\n",
        "\n",
        "        # The convention in BERT is:\n",
        "        # (a) For sequence pairs:\n",
        "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "        #  type_ids: 0   0  0    0    0     0       0 0    1  1  1  1   1 1\n",
        "        # (b) For single sequences:\n",
        "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
        "        #  type_ids: 0   0   0   0  0     0 0\n",
        "        #\n",
        "        # Where \"type_ids\" are used to indicate whether this is the first\n",
        "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "        # embedding vector (and position vector). This is not *strictly* necessary\n",
        "        # since the [SEP] token unambigiously separates the sequences, but it makes\n",
        "        # it easier for the model to learn the concept of sequences.\n",
        "        #\n",
        "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "        # the entire model is fine-tuned.\n",
        "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
        "        segment_ids = [0] * len(tokens)\n",
        "\n",
        "        if tokens_b:\n",
        "            tokens += tokens_b + [\"[SEP]\"]\n",
        "            segment_ids += [1] * (len(tokens_b) + 1)\n",
        "\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "        # tokens are attended to.\n",
        "        input_mask = [1] * len(input_ids)\n",
        "\n",
        "        # Zero-pad up to the sequence length.\n",
        "        padding = [0] * (max_seq_length - len(input_ids))\n",
        "        input_ids += padding\n",
        "        input_mask += padding\n",
        "        segment_ids += padding\n",
        "\n",
        "        assert len(input_ids) == max_seq_length\n",
        "        assert len(input_mask) == max_seq_length\n",
        "        assert len(segment_ids) == max_seq_length\n",
        "        \n",
        "        labels_ids = []\n",
        "        for label in example.labels:\n",
        "            labels_ids.append(float(label))\n",
        "\n",
        "#         label_id = label_map[example.label]\n",
        "        if ex_index < 0:\n",
        "            logger.info(\"*** Example ***\")\n",
        "            logger.info(\"guid: %s\" % (example.guid))\n",
        "            logger.info(\"tokens: %s\" % \" \".join(\n",
        "                    [str(x) for x in tokens]))\n",
        "            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
        "            logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
        "            logger.info(\n",
        "                    \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
        "            logger.info(\"label: %s (id = %s)\" % (example.labels, labels_ids))\n",
        "\n",
        "        features.append(\n",
        "                InputFeatures(input_ids=input_ids,\n",
        "                              input_mask=input_mask,\n",
        "                              segment_ids=segment_ids,\n",
        "                              label_ids=labels_ids))\n",
        "    return features"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22CXpwG9osCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "    # This is a simple heuristic which will always truncate the longer sequence\n",
        "    # one token at a time. This makes more sense than truncating an equal percent\n",
        "    # of tokens from each, since if one sequence is very short then each token\n",
        "    # that's truncated likely contains more information than a longer sequence.\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWhZZ_SYosCz",
        "colab_type": "text"
      },
      "source": [
        "### Metric Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW-87dTYosCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(out, labels):\n",
        "    outputs = np.argmax(out, axis=1)\n",
        "    return np.sum(outputs == labels)\n",
        "\n",
        "def accuracy_thresh(y_pred:Tensor, y_true:Tensor, thresh:float=0.5, sigmoid:bool=True):\n",
        "    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n",
        "    if sigmoid: y_pred = y_pred.sigmoid()\n",
        "#     return ((y_pred>thresh)==y_true.byte()).float().mean().item()\n",
        "    return np.mean(((y_pred>thresh)==y_true.byte()).float().cpu().numpy(), axis=1).sum()\n",
        "\n",
        "\n",
        "def accuracy_thresh_test(y_pred:Tensor, y_true:Tensor, thresh:float=0.5, sigmoid:bool=True):\n",
        "    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n",
        "    if sigmoid: y_pred = y_pred.sigmoid()\n",
        "#     return ((y_pred>thresh)==y_true.byte()).float().mean().item()\n",
        "    return np.mean((y_pred>thresh)==y_true.float()).sum()\n",
        "\n",
        "\n",
        "def fbeta(y_pred:Tensor, y_true:Tensor, thresh:float=0.2, beta:float=2, eps:float=1e-9, sigmoid:bool=True):\n",
        "    \"Computes the f_beta between `preds` and `targets`\"\n",
        "    beta2 = beta ** 2\n",
        "    if sigmoid: y_pred = y_pred.sigmoid()\n",
        "    y_pred = (y_pred>thresh).float()\n",
        "    y_true = y_true.float()\n",
        "    TP = (y_pred*y_true).sum(dim=1)\n",
        "    prec = TP/(y_pred.sum(dim=1)+eps)\n",
        "    rec = TP/(y_true.sum(dim=1)+eps)\n",
        "    res = (prec*rec)/(prec*beta2+rec+eps)*(1+beta2)\n",
        "    return res.mean().item(),prec, rec"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePsoi7YWosC1",
        "colab_type": "text"
      },
      "source": [
        "### Training Warmup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGmwFFb8osC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def warmup_linear(x, warmup=0.002):\n",
        "    if x < warmup:\n",
        "        return x/warmup\n",
        "    return 1.0 - x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av0p85CzosC4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ae387b0-3444-45d3-c909-b73f8d50d361"
      },
      "source": [
        "processors = {\n",
        "    \"toxic_multilabel\": MultiLabelTextProcessor\n",
        "}\n",
        "\n",
        "# Setup GPU parameters\n",
        "\n",
        "if args[\"local_rank\"] == -1 or args[\"no_cuda\"]:\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args[\"no_cuda\"] else \"cpu\")\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "#     n_gpu = 1\n",
        "else:\n",
        "    torch.cuda.set_device(args['local_rank'])\n",
        "    device = torch.device(\"cuda\", args['local_rank'])\n",
        "    n_gpu = 1\n",
        "    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
        "    torch.distributed.init_process_group(backend='nccl')\n",
        "logger.info(\"device: {} n_gpu: {}, distributed training: {}, 16-bits training: {}\".format(\n",
        "        device, n_gpu, bool(args['local_rank'] != -1), args['fp16']))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07/03/2020 07:49:39 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzkDXJU6osC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args['train_batch_size'] = int(args['train_batch_size'] / args['gradient_accumulation_steps'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pK34ee3osC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.seed(args['seed'])\n",
        "np.random.seed(args['seed'])\n",
        "torch.manual_seed(args['seed'])\n",
        "if n_gpu > 0:\n",
        "    torch.cuda.manual_seed_all(args['seed'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uA6T3ZrosDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "task_name = args['task_name'].lower()\n",
        "\n",
        "if task_name not in processors:\n",
        "    raise ValueError(\"Task not found: %s\" % (task_name))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn512PxLosDC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "109d5470-ff5a-4a3e-9343-191b3a73da4b"
      },
      "source": [
        "processor = processors[task_name](args['data_dir'])\n",
        "label_list = processor.get_labels()\n",
        "num_labels = len(label_list)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root Directory  /content/drive/My Drive/Deep Leaning Project - COVID 19 Tweets Analysis/Tweets Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eVJ-Ri2osDE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "498ca7e6-19cc-465b-90ae-b1e7c9680fa0"
      },
      "source": [
        "label_list"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array(['anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise',\n",
              "        'trust'], dtype=object)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TvtmMZrosDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "968f3946-1b75-4646-8b49-6d40bff51e2d"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(args['bert_model'], do_lower_case=args['do_lower_case'])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07/03/2020 07:49:45 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file /content/drive/My Drive/Deep Leaning Project - COVID 19 Tweets Analysis/uncased_L-12_H-768_A-12/vocab.txt\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI7LpfZmosDI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c2703cce-dcfb-4be6-df88-41d5b4b6f950"
      },
      "source": [
        "train_examples = None\n",
        "num_train_steps = None\n",
        "if args['do_train']:\n",
        "    train_examples = processor.get_train_examples(args['full_data_dir'], size=args['train_size'])\n",
        "#     train_examples = processor.get_train_examples(args['data_dir'], size=args['train_size'])\n",
        "    num_train_steps = int(\n",
        "        len(train_examples) / args['train_batch_size'] / args['gradient_accumulation_steps'] * args['num_train_epochs'])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07/03/2020 07:49:46 - INFO - __main__ -   LOOKING AT /content/drive/My Drive/Deep Leaning Project - COVID 19 Tweets Analysis/Tweets Data/train.txt\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXsugFhKosDK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "outputId": "824e2d7f-bb43-4f33-aa36-3b4ed6d254d4"
      },
      "source": [
        "# Prepare model\n",
        "def get_model():\n",
        "#     pdb.set_trace()\n",
        "#     if model_state_dict:\n",
        "#         model = BertForMultiLabelSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 11, state_dict=model_state_dict)\n",
        "#     else:\n",
        "    model = BertForMultiLabelSequenceClassification.from_pretrained('bert-base-uncased', num_labels = num_labels)\n",
        "    return model\n",
        "\n",
        "model = get_model()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07/03/2020 07:49:47 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "07/03/2020 07:49:47 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "07/03/2020 07:49:47 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "07/03/2020 07:49:54 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "07/03/2020 07:49:54 - WARNING - transformers.modeling_utils -   Some weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5txztoIosDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "if args['fp16']:\n",
        "    model.half()\n",
        "model.to(device)\n",
        "if args['local_rank'] != -1:\n",
        "    try:\n",
        "        from apex.parallel import DistributedDataParallel as DDP\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
        "\n",
        "    model = DDP(model)\n",
        "elif n_gpu > 1:\n",
        "    model = torch.nn.DataParallel(model)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud6W504hosDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim.lr_scheduler import _LRScheduler, Optimizer\n",
        "\n",
        "class CyclicLR(object):\n",
        "    \"\"\"Sets the learning rate of each parameter group according to\n",
        "    cyclical learning rate policy (CLR). The policy cycles the learning\n",
        "    rate between two boundaries with a constant frequency, as detailed in\n",
        "    the paper `Cyclical Learning Rates for Training Neural Networks`_.\n",
        "    The distance between the two boundaries can be scaled on a per-iteration\n",
        "    or per-cycle basis.\n",
        "    Cyclical learning rate policy changes the learning rate after every batch.\n",
        "    `batch_step` should be called after a batch has been used for training.\n",
        "    To resume training, save `last_batch_iteration` and use it to instantiate `CycleLR`.\n",
        "    This class has three built-in policies, as put forth in the paper:\n",
        "    \"triangular\":\n",
        "        A basic triangular cycle w/ no amplitude scaling.\n",
        "    \"triangular2\":\n",
        "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
        "    \"exp_range\":\n",
        "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each\n",
        "        cycle iteration.\n",
        "    This implementation was adapted from the github repo: `bckenstler/CLR`_\n",
        "    Args:\n",
        "        optimizer (Optimizer): Wrapped optimizer.\n",
        "        base_lr (float or list): Initial learning rate which is the\n",
        "            lower boundary in the cycle for eachparam groups.\n",
        "            Default: 0.001\n",
        "        max_lr (float or list): Upper boundaries in the cycle for\n",
        "            each parameter group. Functionally,\n",
        "            it defines the cycle amplitude (max_lr - base_lr).\n",
        "            The lr at any cycle is the sum of base_lr\n",
        "            and some scaling of the amplitude; therefore\n",
        "            max_lr may not actually be reached depending on\n",
        "            scaling function. Default: 0.006\n",
        "        step_size (int): Number of training iterations per\n",
        "            half cycle. Authors suggest setting step_size\n",
        "            2-8 x training iterations in epoch. Default: 2000\n",
        "        mode (str): One of {triangular, triangular2, exp_range}.\n",
        "            Values correspond to policies detailed above.\n",
        "            If scale_fn is not None, this argument is ignored.\n",
        "            Default: 'triangular'\n",
        "        gamma (float): Constant in 'exp_range' scaling function:\n",
        "            gamma**(cycle iterations)\n",
        "            Default: 1.0\n",
        "        scale_fn (function): Custom scaling policy defined by a single\n",
        "            argument lambda function, where\n",
        "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
        "            mode paramater is ignored\n",
        "            Default: None\n",
        "        scale_mode (str): {'cycle', 'iterations'}.\n",
        "            Defines whether scale_fn is evaluated on\n",
        "            cycle number or cycle iterations (training\n",
        "            iterations since start of cycle).\n",
        "            Default: 'cycle'\n",
        "        last_batch_iteration (int): The index of the last batch. Default: -1\n",
        "    Example:\n",
        "        >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "        >>> scheduler = torch.optim.CyclicLR(optimizer)\n",
        "        >>> data_loader = torch.utils.data.DataLoader(...)\n",
        "        >>> for epoch in range(10):\n",
        "        >>>     for batch in data_loader:\n",
        "        >>>         scheduler.batch_step()\n",
        "        >>>         train_batch(...)\n",
        "    .. _Cyclical Learning Rates for Training Neural Networks: https://arxiv.org/abs/1506.01186\n",
        "    .. _bckenstler/CLR: https://github.com/bckenstler/CLR\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, optimizer, base_lr=1e-3, max_lr=6e-3,\n",
        "                 step_size=2000, mode='triangular', gamma=1.,\n",
        "                 scale_fn=None, scale_mode='cycle', last_batch_iteration=-1):\n",
        "\n",
        "#         if not isinstance(optimizer, Optimizer):\n",
        "#             raise TypeError('{} is not an Optimizer'.format(\n",
        "#                 type(optimizer).__name__))\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        if isinstance(base_lr, list) or isinstance(base_lr, tuple):\n",
        "            if len(base_lr) != len(optimizer.param_groups):\n",
        "                raise ValueError(\"expected {} base_lr, got {}\".format(\n",
        "                    len(optimizer.param_groups), len(base_lr)))\n",
        "            self.base_lrs = list(base_lr)\n",
        "        else:\n",
        "            self.base_lrs = [base_lr] * len(optimizer.param_groups)\n",
        "\n",
        "        if isinstance(max_lr, list) or isinstance(max_lr, tuple):\n",
        "            if len(max_lr) != len(optimizer.param_groups):\n",
        "                raise ValueError(\"expected {} max_lr, got {}\".format(\n",
        "                    len(optimizer.param_groups), len(max_lr)))\n",
        "            self.max_lrs = list(max_lr)\n",
        "        else:\n",
        "            self.max_lrs = [max_lr] * len(optimizer.param_groups)\n",
        "\n",
        "        self.step_size = step_size\n",
        "\n",
        "        if mode not in ['triangular', 'triangular2', 'exp_range'] \\\n",
        "                and scale_fn is None:\n",
        "            raise ValueError('mode is invalid and scale_fn is None')\n",
        "\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "\n",
        "        if scale_fn is None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = self._triangular_scale_fn\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = self._triangular2_scale_fn\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = self._exp_range_scale_fn\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "\n",
        "        self.batch_step(last_batch_iteration + 1)\n",
        "        self.last_batch_iteration = last_batch_iteration\n",
        "\n",
        "    def batch_step(self, batch_iteration=None):\n",
        "        if batch_iteration is None:\n",
        "            batch_iteration = self.last_batch_iteration + 1\n",
        "        self.last_batch_iteration = batch_iteration\n",
        "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "    def _triangular_scale_fn(self, x):\n",
        "        return 1.\n",
        "\n",
        "    def _triangular2_scale_fn(self, x):\n",
        "        return 1 / (2. ** (x - 1))\n",
        "\n",
        "    def _exp_range_scale_fn(self, x):\n",
        "        return self.gamma**(x)\n",
        "\n",
        "    def get_lr(self):\n",
        "        step_size = float(self.step_size)\n",
        "        cycle = np.floor(1 + self.last_batch_iteration / (2 * step_size))\n",
        "        x = np.abs(self.last_batch_iteration / step_size - 2 * cycle + 1)\n",
        "\n",
        "        lrs = []\n",
        "        param_lrs = zip(self.optimizer.param_groups, self.base_lrs, self.max_lrs)\n",
        "        for param_group, base_lr, max_lr in param_lrs:\n",
        "            base_height = (max_lr - base_lr) * np.maximum(0, (1 - x))\n",
        "            if self.scale_mode == 'cycle':\n",
        "                lr = base_lr + base_height * self.scale_fn(cycle)\n",
        "            else:\n",
        "                lr = base_lr + base_height * self.scale_fn(self.last_batch_iteration)\n",
        "            lrs.append(lr)\n",
        "        return lrs"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrEFnyq5osDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare optimizer\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "t_total = num_train_steps\n",
        "if args['local_rank'] != -1:\n",
        "    t_total = t_total // torch.distributed.get_world_size()\n",
        "if args['fp16']:\n",
        "    try:\n",
        "        from apex.optimizers import FP16_Optimizer\n",
        "        from apex.optimizers import FusedAdam\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
        "\n",
        "    optimizer = FusedAdam(optimizer_grouped_parameters,\n",
        "                          lr=args['learning_rate'],\n",
        "                          bias_correction=False,\n",
        "                          max_grad_norm=1.0)\n",
        "    if args['loss_scale'] == 0:\n",
        "        optimizer = FP16_Optimizer(optimizer, dynamic_loss_scale=True)\n",
        "    else:\n",
        "        optimizer = FP16_Optimizer(optimizer, static_loss_scale=args['loss_scale'])\n",
        "\n",
        "else:\n",
        "    optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                         lr=args['learning_rate'],\n",
        "                         warmup=args['warmup_proportion'],\n",
        "                         t_total=t_total)\n",
        "\n",
        "scheduler = CyclicLR(optimizer, base_lr=2e-5, max_lr=5e-5, step_size=2500, last_batch_iteration=0)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBKhFqDDosDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Eval Fn\n",
        "eval_examples = processor.get_dev_examples(args['data_dir'], size=args['val_size'])\n",
        "def eval():\n",
        "    args['output_dir'].mkdir(exist_ok=True)\n",
        "\n",
        "    \n",
        "    eval_features = convert_examples_to_features(\n",
        "        eval_examples, label_list, args['max_seq_length'], tokenizer)\n",
        "    logger.info(\"***** Running evaluation *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(eval_examples))\n",
        "    logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n",
        "    all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
        "    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
        "    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
        "    all_label_ids = torch.tensor([f.label_ids for f in eval_features], dtype=torch.float)\n",
        "    eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
        "\n",
        "    # Run prediction for full data\n",
        "    eval_sampler = SequentialSampler(eval_data)\n",
        "    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args['eval_batch_size'])\n",
        "    \n",
        "    all_logits = None\n",
        "    all_labels = None\n",
        "    \n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    for input_ids, input_mask, segment_ids, label_ids in eval_dataloader:\n",
        "        input_ids = input_ids.to(device)\n",
        "        input_mask = input_mask.to(device)\n",
        "        segment_ids = segment_ids.to(device)\n",
        "        label_ids = label_ids.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            tmp_eval_loss, logit = model(input_ids, segment_ids, input_mask, label_ids)\n",
        "            logits = model(input_ids, segment_ids, input_mask)\n",
        "\n",
        "\n",
        "#         logits = logits.detach().cpu().numpy()\n",
        "#         label_ids = label_ids.to('cpu').numpy()\n",
        "#         tmp_eval_accuracy = accuracy(logits, label_ids)\n",
        "        tmp_eval_accuracy = accuracy_thresh(logits, label_ids)\n",
        "\n",
        "        res, precision, recall = fbeta(logits, label_ids) \n",
        "        \n",
        "        ########### saving for later use ################\n",
        "        model.validation_batch_true.append(label_ids)  \n",
        "        model.validation_batch_predicted.append(logits) \n",
        "        model.validation_batch_precision.append(precision)\n",
        "        model.validation_batch_recall.append(recall)\n",
        "\n",
        "        if all_logits is None:\n",
        "            all_logits = logits.detach().cpu().numpy()\n",
        "        else:\n",
        "            all_logits = np.concatenate((all_logits, logits.detach().cpu().numpy()), axis=0)\n",
        "            \n",
        "        if all_labels is None:\n",
        "            all_labels = label_ids.detach().cpu().numpy()\n",
        "        else:    \n",
        "            all_labels = np.concatenate((all_labels, label_ids.detach().cpu().numpy()), axis=0)\n",
        "        \n",
        "\n",
        "        eval_loss += tmp_eval_loss.mean().item()\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        nb_eval_examples += input_ids.size(0)\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_examples\n",
        "    \n",
        "#     ROC-AUC calcualation\n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    \n",
        "    for i in range(num_labels):\n",
        "        fpr[i], tpr[i], _ = roc_curve(all_labels[:, i], all_logits[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "        \n",
        "    # Compute micro-average ROC curve and ROC area\n",
        "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(all_labels.ravel(), all_logits.ravel())\n",
        "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "    result = {'eval_loss': eval_loss,\n",
        "              'eval_accuracy': eval_accuracy,\n",
        "#               'loss': tr_loss/nb_tr_steps,\n",
        "              'roc_auc': roc_auc  }\n",
        "\n",
        "  \n",
        "    model.epoch_validation_loss.append(eval_loss) \n",
        "    model.epoch_validation_accuracy.append(eval_accuracy) \n",
        "\n",
        "\n",
        "    output_eval_file = os.path.join(args['output_dir'], \"eval_results.txt\")\n",
        "    with open(output_eval_file, \"w\") as writer:\n",
        "        logger.info(\"***** Eval results *****\")\n",
        "        for key in sorted(result.keys()):\n",
        "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "    return result"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM4oqizhosDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features = convert_examples_to_features(train_examples, label_list, args['max_seq_length'], tokenizer)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8MCL4OjosDX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "b1ca547b-7702-4916-fbb5-1e790dcd820f"
      },
      "source": [
        "logger.info(\"***** Running training *****\")\n",
        "logger.info(\"  Num examples = %d\", len(train_examples))\n",
        "logger.info(\"  Batch size = %d\", args['train_batch_size'])\n",
        "logger.info(\"  Num steps = %d\", num_train_steps)\n",
        "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
        "all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
        "all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
        "all_label_ids = torch.tensor([f.label_ids for f in train_features], dtype=torch.float)\n",
        "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
        "if args['local_rank'] == -1:\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "else:\n",
        "    train_sampler = DistributedSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args['train_batch_size'])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07/03/2020 07:50:16 - INFO - __main__ -   ***** Running training *****\n",
            "07/03/2020 07:50:16 - INFO - __main__ -     Num examples = 6838\n",
            "07/03/2020 07:50:16 - INFO - __main__ -     Batch size = 20\n",
            "07/03/2020 07:50:16 - INFO - __main__ -     Num steps = 683\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1-SZzqSosDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook as tqdm"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa-x8Dk7osDc",
        "colab_type": "text"
      },
      "source": [
        "### Train Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxfWBbAMosDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(num_epocs=args['num_train_epochs']):\n",
        "    global_step = 0\n",
        "    model.train()\n",
        "    for i_ in tqdm(range(int(num_epocs)), desc=\"Epoch\"):\n",
        "\n",
        "        model.train_batch_true.clear()\n",
        "        model.train_batch_predicted.clear()\n",
        "        model.train_batch_precision.clear()\n",
        "        model.train_batch_recall.clear()\n",
        "        \n",
        "        model.validation_batch_true.clear()\n",
        "        model.validation_batch_predicted.clear()\n",
        "        model.validation_batch_precision.clear()\n",
        "        model.validation_batch_recall.clear()\n",
        "\n",
        "\n",
        "        tr_loss = 0\n",
        "        nb_tr_examples, nb_tr_steps = 0, 0\n",
        "        for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
        "\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, input_mask, segment_ids, label_ids = batch\n",
        "            loss, logits = model(input_ids, segment_ids, input_mask, label_ids)\n",
        "\n",
        "            if n_gpu > 1:\n",
        "                loss = loss.mean() # mean() to average on multi-gpu.\n",
        "            if args['gradient_accumulation_steps'] > 1:\n",
        "                loss = loss / args['gradient_accumulation_steps']\n",
        "\n",
        "            if args['fp16']:\n",
        "                optimizer.backward(loss)\n",
        "            else:\n",
        "                loss.backward()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            nb_tr_examples += input_ids.size(0)\n",
        "            nb_tr_steps += 1\n",
        "            if (step + 1) % args['gradient_accumulation_steps'] == 0:\n",
        "    #             scheduler.batch_step()\n",
        "                # modify learning rate with special warm up BERT uses\n",
        "                lr_this_step = args['learning_rate'] * warmup_linear(global_step/t_total, args['warmup_proportion'])\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = lr_this_step\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "\n",
        "            res, precision, recall = fbeta(logits, label_ids) \n",
        "\n",
        "            model.train_batch_true.append(label_ids) \n",
        "            model.train_batch_predicted.append(logits) \n",
        "            model.train_batch_precision.append(precision)\n",
        "            model.train_batch_recall.append(recall)\n",
        "        \n",
        "        model.epoch_train_loss.append(tr_loss / nb_tr_steps) \n",
        "        model.epoch_train_accuracy.append(tr_loss / nb_tr_steps) \n",
        "\n",
        "\n",
        "        logger.info('Loss after epoc {}'.format(tr_loss / nb_tr_steps))\n",
        "        logger.info('Eval after epoc {}'.format(i_+1))\n",
        "        eval()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sxiBim2Y2PT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7af9a322-fe28-478b-aa28-26e0b1d30669"
      },
      "source": [
        "model.get_ecoder_layers_count()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uXSHap9osDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.unfreeze_bert_encoder_count(110)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE5nv3eMosDj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617,
          "referenced_widgets": [
            "cd308b3bd4134ba99b7d868b4deaef43",
            "08b33e92af7f4581831699c4cf6631e1",
            "90dc5723a3a64a3aa019243661af1d76",
            "e3878d1e644f459fb54a8ea88727b30a",
            "9f2c3288f8cd4c2694c3aa15a2870d48",
            "eb226757053342ff8812f57e5672eb7f",
            "bbce93acaa7b42ffaf4154d6e0f0f1fe",
            "c9cd9c9525d343d196bdfb2263e08c6a",
            "7a8c96ea0f924c308ebb4791f2f54b46",
            "ec21b943c7394795bf1e3c19b5ae0c9b",
            "35ac0b5193ef40a9923dea0ad4feb6de",
            "21f5f0af84774fbca3cdc0a314a58774",
            "a61629823b2747258c78fef84ce2159a",
            "8f367454ee9846f8b2930cd1504e05ce",
            "1ea1c71dba304112a854e9436c1cd89b",
            "e72fd669e28b466a8cff7d51086caacb",
            "1633de3b792641afb740b18a36ef93fe",
            "0d25d5cd3d0b48e6b2c2db004d24c95b",
            "856bca33d68141b484c560fe53f199e9",
            "24365822fab84deb8e025629e5e8ab12",
            "90792c15090b4df69b56acc1851041e9",
            "6fe061d1269b48649e1e38e90ddfca88",
            "aaefbec08ebb4642b2c77063370e0d5c",
            "4b03ffeb71a04a08a684b76de011713c"
          ]
        },
        "outputId": "c4edfcc2-db4e-41c0-8855-58bd27bd54ae"
      },
      "source": [
        "fit()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd308b3bd4134ba99b7d868b4deaef43",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=2.0, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a8c96ea0f924c308ebb4791f2f54b46",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=342.0, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n",
            "07/03/2020 08:05:43 - INFO - __main__ -   Loss after epoc 0.4923746181510345\n",
            "07/03/2020 08:05:43 - INFO - __main__ -   Eval after epoc 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "07/03/2020 08:05:43 - INFO - __main__ -   ***** Running evaluation *****\n",
            "07/03/2020 08:05:43 - INFO - __main__ -     Num examples = 886\n",
            "07/03/2020 08:05:43 - INFO - __main__ -     Batch size = 20\n",
            "07/03/2020 08:07:36 - INFO - __main__ -   ***** Eval results *****\n",
            "07/03/2020 08:07:36 - INFO - __main__ -     eval_accuracy = 0.7782680455502753\n",
            "07/03/2020 08:07:36 - INFO - __main__ -     eval_loss = 0.46820061537954544\n",
            "07/03/2020 08:07:36 - INFO - __main__ -     roc_auc = {0: 0.5825897200678286, 'micro': 0.7355662205020564}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1633de3b792641afb740b18a36ef93fe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=342.0, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "07/03/2020 08:22:22 - INFO - __main__ -   Loss after epoc 0.42287319105619575\n",
            "07/03/2020 08:22:22 - INFO - __main__ -   Eval after epoc 2\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "07/03/2020 08:22:22 - INFO - __main__ -   ***** Running evaluation *****\n",
            "07/03/2020 08:22:22 - INFO - __main__ -     Num examples = 886\n",
            "07/03/2020 08:22:22 - INFO - __main__ -     Batch size = 20\n",
            "07/03/2020 08:24:14 - INFO - __main__ -   ***** Eval results *****\n",
            "07/03/2020 08:24:14 - INFO - __main__ -     eval_accuracy = 0.8387030737125577\n",
            "07/03/2020 08:24:14 - INFO - __main__ -     eval_loss = 0.39612749881214565\n",
            "07/03/2020 08:24:14 - INFO - __main__ -     roc_auc = {0: 0.8387401662357878, 'micro': 0.8285014780810538}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOnLoVXm2ruj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Fzd9oAdwu-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "outputId": "3f8427f9-6ad2-47e6-fe06-032b2da0357b"
      },
      "source": [
        "print (\"training accuracy: \", model.epoch_train_accuracy)\n",
        "print (\"training loss: \", model.epoch_train_loss)\n",
        "print (\"validation accuracy: \", model.epoch_validation_accuracy)\n",
        "print (\"validation loss: \", model.epoch_validation_loss)\n",
        "\n",
        "plt.plot(range(0,len(model.epoch_validation_loss)), model.epoch_validation_loss, \"r\", label = \"Validation Loss\") \n",
        "plt.plot(range(0,len(model.epoch_train_loss)), model.epoch_train_loss, \"g\", label = \"Training Loss\") \n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss graph\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(0,len(model.epoch_validation_accuracy)), model.epoch_validation_accuracy, \"*-\", label = \"Validation Accuracy\") \n",
        "plt.plot(range(0,len(model.epoch_train_accuracy)), model.epoch_train_accuracy, \"g\", label = \"Training Accuracy\") \n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy graph\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training accuracy:  [0.4923746181510345, 0.42287319105619575]\n",
            "training loss:  [0.4923746181510345, 0.42287319105619575]\n",
            "validation accuracy:  [0.7782680455502753, 0.8387030737125577]\n",
            "validation loss:  [0.46820061537954544, 0.39612749881214565]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_ShFKz-osDm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "10d59064-cb33-4a7e-d1eb-561885845c94"
      },
      "source": [
        "\n",
        "# Save a trained model\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
        "output_model_file = os.path.join(\"/content/drive/My Drive/DL_Project/BERT_Trained_Model\", \"finetuned_Bert_tweet_model.bin\")\n",
        "torch.save(model_to_save.state_dict(), output_model_file)\n",
        "\n",
        "# # Load a trained model that you have fine-tuned\n",
        "# model_state_dict = torch.load(output_model_file)\n",
        "# model = BertForMultiLabelSequenceClassification.from_pretrained(args['bert_model'], num_labels = num_labels, state_dict=model_state_dict)\n",
        "# model.to(device)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-e86a79ecafd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_to_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'module'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmodel\u001b[0m  \u001b[0;31m# Only save the model it-self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput_model_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/DL_Project/BERT_Trained_Model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"finetuned_Bert_tweet_model.bin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_save\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_model_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# # Load a trained model that you have fine-tuned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/DL_Project/BERT_Trained_Model/finetuned_Bert_tweet_model.bin'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0irnMoRbosDp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b08f87d2-c80b-4e9c-97f7-fe2560aaa810"
      },
      "source": [
        "model"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMultiLabelSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxQ3GZ_O4bVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, jaccard_similarity_score, \\\n",
        "    classification_report, precision_score, recall_score, f1_score"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lkwvslO0PQIG",
        "colab": {}
      },
      "source": [
        "def predict(model, path, test_filename='test.txt'):\n",
        "    predict_processor = MultiLabelTextProcessor(path)\n",
        "    test_examples = predict_processor.get_test_examples(path, test_filename, size=-1)\n",
        "    \n",
        "    test_file = pd.read_csv(os.path.join(path, test_filename), sep= \"\\t\")\n",
        "    emotions = test_file.columns[2:]\n",
        "    \n",
        "    # Hold input data for returning it \n",
        "    input_data = [{ 'id': input_example.guid, 'comment_text': input_example.text_a } for input_example in test_examples]\n",
        "\n",
        "    test_features = convert_examples_to_features(\n",
        "        test_examples, label_list, args['max_seq_length'], tokenizer)\n",
        "    \n",
        "    \n",
        "\n",
        "    logger.info(\"***** Running prediction *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(test_examples))\n",
        "    logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n",
        "\n",
        "\n",
        "    all_input_ids = torch.tensor([f.input_ids for f in test_features], dtype=torch.long)\n",
        "    all_input_mask = torch.tensor([f.input_mask for f in test_features], dtype=torch.long)\n",
        "    all_segment_ids = torch.tensor([f.segment_ids for f in test_features], dtype=torch.long)\n",
        "    all_labels_ids = torch.tensor([f.label_ids for f in test_features], dtype=torch.float)\n",
        "    print (all_input_ids.shape, all_input_mask.shape, all_segment_ids.shape, all_labels_ids.shape)\n",
        "    test_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_labels_ids)\n",
        "    \n",
        "    # Run prediction for full data\n",
        "    test_sampler = SequentialSampler(test_data)\n",
        "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=args['eval_batch_size'])\n",
        "    \n",
        "    all_logits = None\n",
        "    all_labels = None\n",
        "    test_loss  = 0\n",
        "    model.eval()\n",
        "    test_loss, test_accuracy = 0, 0\n",
        "    nb_test_steps, nb_test_examples = 0, 0\n",
        "\n",
        "    for step, batch in enumerate(tqdm(test_dataloader, desc=\"Prediction Iteration\")):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        input_ids, input_mask, segment_ids, label_ids = batch\n",
        "        \n",
        "        \n",
        "        with torch.no_grad():\n",
        "            loss, pred_logits = model(input_ids, segment_ids, input_mask, label_ids)\n",
        "\n",
        "            logits = model(input_ids, segment_ids, input_mask)\n",
        "        tmp_test_accuracy = accuracy_thresh(logits, label_ids)\n",
        "\n",
        "        logits = logits.sigmoid()\n",
        "\n",
        "        if all_logits is None:\n",
        "            all_logits = logits.detach().cpu().numpy()\n",
        "        else:\n",
        "            all_logits = np.concatenate((all_logits, logits.detach().cpu().numpy()), axis=0)\n",
        "        \n",
        "        if all_labels is None:\n",
        "            all_labels = label_ids.detach().cpu().numpy()\n",
        "        else:\n",
        "            all_labels = np.concatenate((all_labels, label_ids.detach().cpu().numpy()), axis=0)\n",
        "           \n",
        "        \n",
        "        test_loss += loss.item()\n",
        "        nb_test_examples += input_ids.size(0)\n",
        "        nb_test_steps += 1\n",
        "        test_accuracy += tmp_test_accuracy\n",
        "        \n",
        "        res, precision, recall = fbeta(logits, label_ids) \n",
        "        \n",
        "        model.test_batch_true.append(label_ids)\n",
        "        model.test_batch_predicted.append(logits)\n",
        "        model.test_batch_precision.append(precision)\n",
        "        model.test_batch_recall.append(recall)\n",
        "\n",
        "\n",
        "        if n_gpu > 1:\n",
        "            loss = loss.mean() # mean() to average on multi-gpu.\n",
        "        if args['gradient_accumulation_steps'] > 1:\n",
        "            loss = loss / args['gradient_accumulation_steps']\n",
        "\n",
        "  \n",
        "    model.test_accuracy = test_accuracy/ nb_test_examples\n",
        "    model.test_loss = test_loss / nb_test_steps\n",
        "    model.epoch_test_loss.append(test_loss / nb_test_steps) \n",
        "    model.epoch_test_accuracy.append(test_accuracy/ nb_test_examples) \n",
        "\n",
        "    all_logits = all_logits>0.2\n",
        "    all_logits = all_logits.astype(int)\n",
        "    all_labels = all_labels.astype(int)\n",
        "\n",
        "    print(\"calculating matrices...\")\n",
        "    # calculate a variety of metrics for comparison\n",
        "    jaccard_sim = jaccard_similarity_score(all_logits, all_labels)\n",
        "    prec_score_micro = precision_score(all_logits, all_labels, average='micro')\n",
        "    prec_score_macro = precision_score(all_logits, all_labels, average='macro')\n",
        "    rec_score_micro = recall_score(all_logits, all_labels, average='micro')\n",
        "    rec_score_macro = recall_score(all_logits, all_labels, average='macro')\n",
        "    f1_micro = f1_score(all_logits, all_labels, average='micro')\n",
        "    f1_macro = f1_score(all_logits, all_labels, average='macro')\n",
        "    class_report = classification_report(all_logits, all_labels, target_names=emotions)\n",
        "\n",
        "    # print metrics to terminal\n",
        "    print(f\"Jaccard Similarity (accuracy): {jaccard_sim}\")\n",
        "    print(f\"Classification Report: \\n{class_report}\")\n",
        "    print(f\"Precision Score (micro): {prec_score_micro}\")\n",
        "    print(f\"Precision Score (macro): {prec_score_macro}\")\n",
        "    print(f\"Recall Score (micro): {rec_score_micro}\")\n",
        "    print(f\"Recall Score (macro): {rec_score_macro}\")\n",
        "    print(f\"f1 Score (micro): {f1_micro}\")\n",
        "    print(f\"f1 Score (macro): {f1_macro}\")\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "    return pd.merge(pd.DataFrame(input_data), pd.DataFrame(all_logits, columns=label_list), left_index=True, right_index=True)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9MbZICtosDv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 808,
          "referenced_widgets": [
            "b6fe1b2a84384404a4612704042740bd",
            "d1e39126cbd14a87b1f2216eb99ba4ba",
            "72ff0b3da31c4fd1919a3a7eb9871a9b",
            "a9c920a672ea488d9c21d52351c74ef8",
            "fd2324baeb654ebf8b4a3aeb80896813",
            "6ab1c473af714a09b8513a92a1939fd1",
            "259c351bb9fd423ab408f530fdabd73e",
            "643aa935801d49ebb970ba3365d47078"
          ]
        },
        "outputId": "fd1df91f-6f5a-499f-a4b8-2808e5ed5efd"
      },
      "source": [
        "all_labels = predict(model, DATA_PATH)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root Directory  /content/drive/My Drive/Deep Leaning Project - COVID 19 Tweets Analysis/Tweets Data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "07/03/2020 09:42:17 - INFO - __main__ -   ***** Running prediction *****\n",
            "07/03/2020 09:42:17 - INFO - __main__ -     Num examples = 3259\n",
            "07/03/2020 09:42:17 - INFO - __main__ -     Batch size = 20\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3259, 512]) torch.Size([3259, 512]) torch.Size([3259, 512]) torch.Size([3259, 11])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6fe1b2a84384404a4612704042740bd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Prediction Iteration', max=163.0, style=ProgressStyle(des…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "calculating matrices...\n",
            "Jaccard Similarity (accuracy): 0.41740674177004344\n",
            "Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.92      0.52      0.67      1955\n",
            "anticipation       0.20      0.12      0.15       693\n",
            "     disgust       0.92      0.52      0.66      1943\n",
            "        fear       0.44      0.22      0.29       998\n",
            "         joy       0.95      0.58      0.72      2388\n",
            "        love       0.77      0.43      0.55       927\n",
            "    optimism       0.88      0.53      0.66      1902\n",
            "   pessimism       0.00      0.00      0.00         4\n",
            "     sadness       0.97      0.34      0.51      2723\n",
            "    surprise       0.00      0.00      0.00         1\n",
            "       trust       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.77      0.45      0.56     13534\n",
            "   macro avg       0.55      0.30      0.38     13534\n",
            "weighted avg       0.85      0.45      0.58     13534\n",
            " samples avg       0.76      0.45      0.55     13534\n",
            "\n",
            "Precision Score (micro): 0.7678231033168128\n",
            "Precision Score (macro): 0.5510800214451407\n",
            "Recall Score (micro): 0.4464312102852076\n",
            "Recall Score (macro): 0.2958112593362103\n",
            "f1 Score (micro): 0.5645937485399244\n",
            "f1 Score (macro): 0.3825157341110465\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKIx-lCeK-MH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "81fc5aa6-d540-4984-b73c-7692bee2131f"
      },
      "source": [
        "\n",
        "print (\"Test Loss\", model.test_loss)\n",
        "print (\"Test Accuracy\", model.test_accuracy)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss 0.4023091012349158\n",
            "Test Accuracy 0.8361181769498326\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr91Au4rosD0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "outputId": "216f0c89-06ea-435a-d0b3-eb72bee778df"
      },
      "source": [
        "result"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>(anger,)</th>\n",
              "      <th>(anticipation,)</th>\n",
              "      <th>(disgust,)</th>\n",
              "      <th>(fear,)</th>\n",
              "      <th>(joy,)</th>\n",
              "      <th>(love,)</th>\n",
              "      <th>(optimism,)</th>\n",
              "      <th>(pessimism,)</th>\n",
              "      <th>(sadness,)</th>\n",
              "      <th>(surprise,)</th>\n",
              "      <th>(trust,)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-En-01559</td>\n",
              "      <td>@Adnan__786__ @AsYouNotWish Dont worry Indian ...</td>\n",
              "      <td>0.585906</td>\n",
              "      <td>0.139105</td>\n",
              "      <td>0.626076</td>\n",
              "      <td>0.258586</td>\n",
              "      <td>0.180707</td>\n",
              "      <td>0.070989</td>\n",
              "      <td>0.162511</td>\n",
              "      <td>0.150562</td>\n",
              "      <td>0.360855</td>\n",
              "      <td>0.082877</td>\n",
              "      <td>0.088378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-En-03739</td>\n",
              "      <td>Academy of Sciences, eschews the normally sobe...</td>\n",
              "      <td>0.520372</td>\n",
              "      <td>0.123621</td>\n",
              "      <td>0.557211</td>\n",
              "      <td>0.204304</td>\n",
              "      <td>0.195251</td>\n",
              "      <td>0.059294</td>\n",
              "      <td>0.167865</td>\n",
              "      <td>0.131246</td>\n",
              "      <td>0.349796</td>\n",
              "      <td>0.060636</td>\n",
              "      <td>0.060387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-En-00385</td>\n",
              "      <td>I blew that opportunity -__- #mad</td>\n",
              "      <td>0.450023</td>\n",
              "      <td>0.116740</td>\n",
              "      <td>0.448963</td>\n",
              "      <td>0.169792</td>\n",
              "      <td>0.233653</td>\n",
              "      <td>0.060843</td>\n",
              "      <td>0.186138</td>\n",
              "      <td>0.108920</td>\n",
              "      <td>0.337107</td>\n",
              "      <td>0.048158</td>\n",
              "      <td>0.045989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-En-03001</td>\n",
              "      <td>This time in 2 weeks I will be 30... 😥</td>\n",
              "      <td>0.152506</td>\n",
              "      <td>0.169308</td>\n",
              "      <td>0.151810</td>\n",
              "      <td>0.133806</td>\n",
              "      <td>0.635167</td>\n",
              "      <td>0.159794</td>\n",
              "      <td>0.492570</td>\n",
              "      <td>0.118757</td>\n",
              "      <td>0.223270</td>\n",
              "      <td>0.058018</td>\n",
              "      <td>0.073931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-En-01988</td>\n",
              "      <td>#Deppression is real. Partners w/ #depressed p...</td>\n",
              "      <td>0.562507</td>\n",
              "      <td>0.129626</td>\n",
              "      <td>0.596044</td>\n",
              "      <td>0.231870</td>\n",
              "      <td>0.184474</td>\n",
              "      <td>0.064798</td>\n",
              "      <td>0.163993</td>\n",
              "      <td>0.140928</td>\n",
              "      <td>0.358496</td>\n",
              "      <td>0.069057</td>\n",
              "      <td>0.069917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3254</th>\n",
              "      <td>2018-En-03848</td>\n",
              "      <td>shaft abrasions from panties merely shifted to...</td>\n",
              "      <td>0.572938</td>\n",
              "      <td>0.130753</td>\n",
              "      <td>0.609118</td>\n",
              "      <td>0.242035</td>\n",
              "      <td>0.183392</td>\n",
              "      <td>0.066936</td>\n",
              "      <td>0.156981</td>\n",
              "      <td>0.141803</td>\n",
              "      <td>0.361304</td>\n",
              "      <td>0.073342</td>\n",
              "      <td>0.075773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3255</th>\n",
              "      <td>2018-En-00416</td>\n",
              "      <td>@lomadia heard of Remothered? Indie horror gam...</td>\n",
              "      <td>0.207312</td>\n",
              "      <td>0.142221</td>\n",
              "      <td>0.204916</td>\n",
              "      <td>0.125765</td>\n",
              "      <td>0.494847</td>\n",
              "      <td>0.106863</td>\n",
              "      <td>0.371279</td>\n",
              "      <td>0.102972</td>\n",
              "      <td>0.231381</td>\n",
              "      <td>0.044852</td>\n",
              "      <td>0.044550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3256</th>\n",
              "      <td>2018-En-03717</td>\n",
              "      <td>All this fake outrage. Y'all need to stop 🤣</td>\n",
              "      <td>0.548233</td>\n",
              "      <td>0.127739</td>\n",
              "      <td>0.581329</td>\n",
              "      <td>0.218448</td>\n",
              "      <td>0.187338</td>\n",
              "      <td>0.062022</td>\n",
              "      <td>0.164434</td>\n",
              "      <td>0.138169</td>\n",
              "      <td>0.356693</td>\n",
              "      <td>0.064775</td>\n",
              "      <td>0.065957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3257</th>\n",
              "      <td>2018-En-03504</td>\n",
              "      <td>Would be ever so grateful if you could record ...</td>\n",
              "      <td>0.133698</td>\n",
              "      <td>0.222044</td>\n",
              "      <td>0.139688</td>\n",
              "      <td>0.146017</td>\n",
              "      <td>0.756552</td>\n",
              "      <td>0.318069</td>\n",
              "      <td>0.610230</td>\n",
              "      <td>0.145410</td>\n",
              "      <td>0.199746</td>\n",
              "      <td>0.111488</td>\n",
              "      <td>0.125194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>2018-En-00115</td>\n",
              "      <td>I'm the wholesome drunk that sends people meme...</td>\n",
              "      <td>0.146786</td>\n",
              "      <td>0.203181</td>\n",
              "      <td>0.145368</td>\n",
              "      <td>0.141753</td>\n",
              "      <td>0.690157</td>\n",
              "      <td>0.219603</td>\n",
              "      <td>0.534162</td>\n",
              "      <td>0.131236</td>\n",
              "      <td>0.220624</td>\n",
              "      <td>0.081838</td>\n",
              "      <td>0.089532</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3259 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ...  (trust,)\n",
              "0     2018-En-01559  ...  0.088378\n",
              "1     2018-En-03739  ...  0.060387\n",
              "2     2018-En-00385  ...  0.045989\n",
              "3     2018-En-03001  ...  0.073931\n",
              "4     2018-En-01988  ...  0.069917\n",
              "...             ...  ...       ...\n",
              "3254  2018-En-03848  ...  0.075773\n",
              "3255  2018-En-00416  ...  0.044550\n",
              "3256  2018-En-03717  ...  0.065957\n",
              "3257  2018-En-03504  ...  0.125194\n",
              "3258  2018-En-00115  ...  0.089532\n",
              "\n",
              "[3259 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gitKx28LH7io",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class OUTPUT_MultiLabelTextProcessor(DataProcessor):\n",
        "    \n",
        "    def __init__(self, data_dir):\n",
        "        self.data_dir = data_dir\n",
        "        self.labels = None\n",
        "        print (\"root Directory \", self.data_dir)\n",
        "    \n",
        "    def get_test_examples(self, data_dir, data_file_name, size=-1):\n",
        "        data_df = pd.read_csv(os.path.join(data_dir, data_file_name))\n",
        "#         data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
        "        if size == -1:\n",
        "            return self._create_examples(data_df, \"test\")\n",
        "        else:\n",
        "            return self._create_examples(data_df.sample(size), \"test\")\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        if self.labels == None:\n",
        "            self.labels = list(pd.read_csv(os.path.join(self.data_dir, \"classes.txt\"),header=None, sep = '\\t').values)\n",
        "        return self.labels\n",
        "\n",
        "    def _create_examples(self, df, set_type, labels_available=False):\n",
        "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "        examples = []\n",
        "        for (i, row) in enumerate(df.values):\n",
        "            guid = row[2]\n",
        "            text_a = str(row[4])\n",
        "            if labels_available:\n",
        "                labels = row[13:]\n",
        "            else:\n",
        "                labels = []\n",
        "            examples.append(\n",
        "                InputExample(guid=guid, text_a=text_a, labels=labels))\n",
        "        return examples\n",
        "        "
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU8W1RrN_sSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label(model, path, test_filename='Tweets_Final_Dataset.csv'):\n",
        "    predict_processor = OUTPUT_MultiLabelTextProcessor(path)\n",
        "    test_examples = predict_processor.get_test_examples(path, test_filename, size=-1)\n",
        "    \n",
        "    # Hold input data for returning it \n",
        "    input_data = pd.read_csv(os.path.join(path, test_filename))\n",
        "\n",
        "    test_features = convert_examples_to_features(\n",
        "        test_examples, label_list, args['max_seq_length'], tokenizer)\n",
        "    \n",
        "    logger.info(\"***** Running prediction *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(test_examples))\n",
        "    logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n",
        "    \n",
        "    all_input_ids = torch.tensor([f.input_ids for f in test_features], dtype=torch.long)\n",
        "    all_input_mask = torch.tensor([f.input_mask for f in test_features], dtype=torch.long)\n",
        "    all_segment_ids = torch.tensor([f.segment_ids for f in test_features], dtype=torch.long)\n",
        "\n",
        "    test_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids)\n",
        "    \n",
        "    # Run prediction for full data\n",
        "    test_sampler = SequentialSampler(test_data)\n",
        "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=args['eval_batch_size'])\n",
        "    \n",
        "    all_logits = None\n",
        "    \n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    for step, batch in enumerate(tqdm(test_dataloader, desc=\"Emotion Labeling Iteration\")):\n",
        "        input_ids, input_mask, segment_ids = batch\n",
        "        input_ids = input_ids.to(device)\n",
        "        input_mask = input_mask.to(device)\n",
        "        segment_ids = segment_ids.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            logits = model(input_ids, segment_ids, input_mask)\n",
        "            logits = logits.sigmoid()\n",
        "\n",
        "        if all_logits is None:\n",
        "            all_logits = logits.detach().cpu().numpy()\n",
        "        else:\n",
        "            all_logits = np.concatenate((all_logits, logits.detach().cpu().numpy()), axis=0)\n",
        "            \n",
        "        \n",
        "       \n",
        "        nb_eval_examples += input_ids.size(0)\n",
        "        nb_eval_steps += 1\n",
        "    all_logits = all_logits>0.2\n",
        "    all_logits = all_logits.astype(int)\n",
        "    return pd.merge(pd.DataFrame(input_data), pd.DataFrame(all_logits, columns=label_list), left_index=True, right_index=True)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cyl9PA2EXLbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labeled_result = label(model, DATA_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWpzLFoARiNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labeled_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPZx3qOWRapw",
        "colab_type": "text"
      },
      "source": [
        "Save Model output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOkpPlapPCVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labeled_result.to_csv(\"/content/drive/My Drive/Deep Leaning Project - COVID 19 Tweets Analysis/Tweets Data/Corona_virus_Tweets/BERT_MODEL_OUTPUT_SemEval_prediction.csv\", index = False )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BsOid3EEb8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}