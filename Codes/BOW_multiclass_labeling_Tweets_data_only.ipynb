{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "This script preprocesses the tweet data similarily to preprocess_tf_binary.py\n",
    "It uses the same script for processing hashtags, emojis and usernames\n",
    "(found at https://gist.github.com/tokestermw/cb87a97113da12acb388)\n",
    "It then uses sklearn libraries to perform multilabel classification on\n",
    "the Bag of Words Model algorithms contained below\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, learning_curve, ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, jaccard_similarity_score, \\\n",
    "    classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FLAGS = re.MULTILINE | re.DOTALL\n",
    "\n",
    "\n",
    "def fix_split(pattern, string):\n",
    "    splits = list((m.start(), m.end()) for m in re.finditer(pattern, string))\n",
    "    starts = [0] + [i[1] for i in splits]\n",
    "    ends = [i[0] for i in splits] + [len(string)]\n",
    "    return [string[start:end] for start, end in zip(starts, ends)]\n",
    "\n",
    "\n",
    "def hashtag(text):\n",
    "    text = text.group()\n",
    "    hashtag_body = text[1:]\n",
    "    if hashtag_body.isupper():\n",
    "        result = \" {} \".format(hashtag_body.lower())\n",
    "    else:\n",
    "        result = \" \".join([\"<hashtag>\"] + fix_split(r\"(?=[A-Z])\", hashtag_body))  # , flags=FLAGS))\n",
    "    return result\n",
    "\n",
    "\n",
    "def allcaps(text):\n",
    "    text = text.group()\n",
    "    return text.lower() + \" <allcaps>\"\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    # Different regex parts for smiley faces\n",
    "    eyes = r\"[8:=;]\"\n",
    "    nose = r\"['`\\-]?\"\n",
    "\n",
    "    def re_sub(pattern, repl):\n",
    "        return re.sub(pattern, repl, text, flags=FLAGS)\n",
    "\n",
    "    text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"<url>\")\n",
    "    text = re_sub(r\"@\\w+\", \"<user>\")\n",
    "    text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n",
    "    text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n",
    "    text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n",
    "    text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n",
    "    text = re_sub(r\"/\", \" / \")\n",
    "    text = re_sub(r\"<3\", \"<heart>\")\n",
    "    text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<number>\")\n",
    "    text = re_sub(r\"#\\S+\", hashtag)\n",
    "    text = re_sub(r\"([!?.]){2,}\", r\"\\1 <repeat>\")\n",
    "    text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n",
    "    text = re_sub(r\"([A-Z]){2,}\", allcaps)\n",
    "\n",
    "    return text.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling_data = pd.read_csv(\"C:/Users/Muhammad/Deep Learning/Final Project/To Label Data/Pre-processed_English_Tweets.csv\")\n",
    "labeling_data['text'] = labeling_data['text'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading\n",
      "Data loaded...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print ('Data loading')\n",
    "train_df = pd.read_csv('C:/Users/Muhammad/Deep Learning/Final Project/SemEval2018-Task1-all-data/English/E-c/train.txt', sep = '\\t')\n",
    "test_df = pd.read_csv('C:/Users/Muhammad/Deep Learning/Final Project/SemEval2018-Task1-all-data/English/E-c/test.txt', sep = '\\t')\n",
    "val_df = pd.read_csv('C:/Users/Muhammad/Deep Learning/Final Project/SemEval2018-Task1-all-data/English/E-c/dev.txt', sep = '\\t')\n",
    "\n",
    "\n",
    "\n",
    "print ('Data loaded...')\n",
    "\n",
    "df = train_df.append(val_df, ignore_index=True)\n",
    "df = df.append(test_df, ignore_index = True)\n",
    "\n",
    "# Clean up training data\n",
    "# df.dropna(axis=0, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df['text'] = df['text'].apply(tokenize)\n",
    "emotions = df.columns[2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df['text']\n",
    "# tweets = tweets.append(labeling_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(tweets), df['text'].shape, labeling_data['text'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets= tweets.values\n",
    "cv = CountVectorizer()\n",
    "tweets_transformed = cv.fit_transform(tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_predict_tokens = tweets_transformed[:232070]\n",
    "# tweets = tweets_transformed[232070:]\n",
    "tweets = tweets_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_predict_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-9f00b42312a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtweets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_predict_tokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'to_predict_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "tweets.shape, to_predict_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Splitted...\n",
      "Model fitting...\n",
      "predicting...\n",
      "calculating matrices...\n",
      "Jaccard Similarity (accuracy): 0.430938292476754\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.69      0.66      0.68      1604\n",
      "anticipation       0.28      0.21      0.24       622\n",
      "     disgust       0.62      0.57      0.59      1628\n",
      "        fear       0.68      0.63      0.65       749\n",
      "         joy       0.74      0.70      0.72      1703\n",
      "        love       0.45      0.40      0.42       500\n",
      "    optimism       0.57      0.55      0.56      1338\n",
      "   pessimism       0.25      0.21      0.23       508\n",
      "     sadness       0.52      0.54      0.53      1300\n",
      "    surprise       0.37      0.19      0.26       222\n",
      "       trust       0.11      0.07      0.09       190\n",
      "\n",
      "   micro avg       0.58      0.54      0.56     10364\n",
      "   macro avg       0.48      0.43      0.45     10364\n",
      "weighted avg       0.57      0.54      0.56     10364\n",
      " samples avg       0.58      0.55      0.53     10364\n",
      "\n",
      "Precision Score (micro): 0.5843272651182255\n",
      "Precision Score (macro): 0.4806987364638368\n",
      "Recall Score (micro): 0.5388846005403319\n",
      "Recall Score (macro): 0.4310149392186924\n",
      "f1 Score (micro): 0.5606866780443731\n",
      "f1 Score (macro): 0.4519733340638368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Muhammad\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Muhammad\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Muhammad\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# separate into data and labels\n",
    "# tweets = df['text'].values\n",
    "labels = df[emotions].values\n",
    "\n",
    "# map tweets to vector representation of the unique words it contains\n",
    "# cv = CountVectorizer()\n",
    "# x_tokens = cv.fit_transform(tweets)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(tweets, labels,\n",
    "                                                  test_size=0.4)\n",
    "print ('Data Splitted...')\n",
    "\n",
    "# suitable classifier models\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=200,)\n",
    "# clf = KNeighborsClassifier()\n",
    "# clf = DecisionTreeClassifier()\n",
    "# clf = RandomForestClassifier()\n",
    "\n",
    "print ('Model fitting...')\n",
    "# fit on the training data\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print (\"predicting...\")\n",
    "# make predictions on testing data\n",
    "predicted = clf.predict(x_val)\n",
    "print(\"calculating matrices...\")\n",
    "# calculate a variety of metrics for comparison\n",
    "jaccard_sim = jaccard_similarity_score(y_val, predicted)\n",
    "prec_score_micro = precision_score(y_val, predicted, average='micro')\n",
    "prec_score_macro = precision_score(y_val, predicted, average='macro')\n",
    "rec_score_micro = recall_score(y_val, predicted, average='micro')\n",
    "rec_score_macro = recall_score(y_val, predicted, average='macro')\n",
    "f1_micro = f1_score(y_val, predicted, average='micro')\n",
    "f1_macro = f1_score(y_val, predicted, average='macro')\n",
    "class_report = classification_report(y_val, predicted, target_names=emotions)\n",
    "\n",
    "# print metrics to terminal\n",
    "print(f\"Jaccard Similarity (accuracy): {jaccard_sim}\")\n",
    "print(f\"Classification Report: \\n{class_report}\")\n",
    "print(f\"Precision Score (micro): {prec_score_micro}\")\n",
    "print(f\"Precision Score (macro): {prec_score_macro}\")\n",
    "print(f\"Recall Score (micro): {rec_score_micro}\")\n",
    "print(f\"Recall Score (macro): {rec_score_macro}\")\n",
    "print(f\"f1 Score (micro): {f1_micro}\")\n",
    "print(f\"f1 Score (macro): {f1_macro}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 0.1406463359126081\n"
     ]
    }
   ],
   "source": [
    "print (\"Prediction Accuracy:\", accuracy_score(y_val, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['anger','anticipation','disgust','fear','joy','love','optimism','pessimism','sadness','surprise','trust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "labels = clf.predict(to_predict_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.merge(pd.DataFrame(labeling_data), pd.DataFrame(labels, columns=label_list), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"C:/Users/Muhammad/Deep Learning/Final Project/To Label Data/BOG_labeled.csv\", index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>display_text_width</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>...</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1240849521011113984</td>\n",
       "      <td>840438614</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>03:55:54</td>\n",
       "      <td>corona time</td>\n",
       "      <td>False</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1240849520381976576</td>\n",
       "      <td>1143505456121307136</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>03:55:54</td>\n",
       "      <td>flexing king u&lt;number&gt;f&lt;number&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1240849519727857664</td>\n",
       "      <td>3449353153</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>03:55:54</td>\n",
       "      <td>everyone looks sick</td>\n",
       "      <td>False</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>51508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1240849521866952704</td>\n",
       "      <td>1511537016</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>03:55:54</td>\n",
       "      <td>corona day &lt;number&gt; feels like sunday</td>\n",
       "      <td>False</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>89818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1240849528414244864</td>\n",
       "      <td>334488003</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>03:55:56</td>\n",
       "      <td>everyone stay home please corona fucks quickly...</td>\n",
       "      <td>False</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>25397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232065</th>\n",
       "      <td>1245982290003591168</td>\n",
       "      <td>787704370527866880</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>07:51:41</td>\n",
       "      <td>please please please people stay fuck home got...</td>\n",
       "      <td>False</td>\n",
       "      <td>259</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232066</th>\n",
       "      <td>1245982289902940160</td>\n",
       "      <td>106725571</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>07:51:41</td>\n",
       "      <td>within means please help fund wildlifeorphan&lt;n...</td>\n",
       "      <td>False</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232067</th>\n",
       "      <td>1245982281132584960</td>\n",
       "      <td>862838468136779776</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>07:51:39</td>\n",
       "      <td>migrant amp refugee camps potential catalysts ...</td>\n",
       "      <td>False</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>c(\"migrants\", \"MigrantsOnTheRoad\", \"Refugees\",...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232068</th>\n",
       "      <td>1245982253731233792</td>\n",
       "      <td>4898066856</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>07:51:33</td>\n",
       "      <td>think good thing pesach tell hashem corona cha...</td>\n",
       "      <td>False</td>\n",
       "      <td>138</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Covid_19</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232069</th>\n",
       "      <td>1245982257745219584</td>\n",
       "      <td>1194762833885638664</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>07:51:34</td>\n",
       "      <td>touch show wash hands u&lt;number&gt;f&lt;number&gt;fc cor...</td>\n",
       "      <td>False</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>466</td>\n",
       "      <td>c(\"corona\", \"coronavirus\")</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232070 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  status_id              user_id        date      time  \\\n",
       "0       1240849521011113984            840438614  2020-03-20  03:55:54   \n",
       "1       1240849520381976576  1143505456121307136  2020-03-20  03:55:54   \n",
       "2       1240849519727857664           3449353153  2020-03-20  03:55:54   \n",
       "3       1240849521866952704           1511537016  2020-03-20  03:55:54   \n",
       "4       1240849528414244864            334488003  2020-03-20  03:55:56   \n",
       "...                     ...                  ...         ...       ...   \n",
       "232065  1245982290003591168   787704370527866880  2020-04-03  07:51:41   \n",
       "232066  1245982289902940160            106725571  2020-04-03  07:51:41   \n",
       "232067  1245982281132584960   862838468136779776  2020-04-03  07:51:39   \n",
       "232068  1245982253731233792           4898066856  2020-04-03  07:51:33   \n",
       "232069  1245982257745219584  1194762833885638664  2020-04-03  07:51:34   \n",
       "\n",
       "                                                     text  is_quote  \\\n",
       "0                                             corona time     False   \n",
       "1                         flexing king u<number>f<number>      True   \n",
       "2                                     everyone looks sick     False   \n",
       "3                   corona day <number> feels like sunday     False   \n",
       "4       everyone stay home please corona fucks quickly...     False   \n",
       "...                                                   ...       ...   \n",
       "232065  please please please people stay fuck home got...     False   \n",
       "232066  within means please help fund wildlifeorphan<n...     False   \n",
       "232067  migrant amp refugee camps potential catalysts ...     False   \n",
       "232068  think good thing pesach tell hashem corona cha...     False   \n",
       "232069  touch show wash hands u<number>f<number>fc cor...     False   \n",
       "\n",
       "        display_text_width  favorite_count  retweet_count  \\\n",
       "0                       43               0              0   \n",
       "1                       16               0              0   \n",
       "2                       67               0          51508   \n",
       "3                       73               0          89818   \n",
       "4                      140               0          25397   \n",
       "...                    ...             ...            ...   \n",
       "232065                 259              10              0   \n",
       "232066                 140               0             11   \n",
       "232067                 271               0              3   \n",
       "232068                 138               2              0   \n",
       "232069                 114               0            466   \n",
       "\n",
       "                                                 hashtags  ... anticipation  \\\n",
       "0                                                     NaN  ...            0   \n",
       "1                                                     NaN  ...            0   \n",
       "2                                                     NaN  ...            0   \n",
       "3                                                     NaN  ...            0   \n",
       "4                                                     NaN  ...            0   \n",
       "...                                                   ...  ...          ...   \n",
       "232065                                                NaN  ...            1   \n",
       "232066                                                NaN  ...            0   \n",
       "232067  c(\"migrants\", \"MigrantsOnTheRoad\", \"Refugees\",...  ...            0   \n",
       "232068                                           Covid_19  ...            1   \n",
       "232069                         c(\"corona\", \"coronavirus\")  ...            1   \n",
       "\n",
       "       disgust  fear  joy  love  optimism  pessimism  sadness  surprise  trust  \n",
       "0            0     0    0     0         0          0        0         0      0  \n",
       "1            0     0    0     0         0          0        0         0      0  \n",
       "2            0     1    0     0         1          0        0         0      0  \n",
       "3            0     0    0     0         0          0        0         0      0  \n",
       "4            0     0    0     0         1          0        0         0      0  \n",
       "...        ...   ...  ...   ...       ...        ...      ...       ...    ...  \n",
       "232065       0     0    0     0         0          0        0         0      0  \n",
       "232066       0     0    0     0         0          0        0         0      0  \n",
       "232067       0     0    0     0         0          1        0         0      1  \n",
       "232068       0     0    0     0         0          0        0         0      0  \n",
       "232069       0     0    0     0         0          0        0         0      0  \n",
       "\n",
       "[232070 rows x 23 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
